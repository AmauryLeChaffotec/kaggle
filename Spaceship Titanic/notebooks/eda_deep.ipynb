{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - Deep EDA\n",
    "\n",
    "**Objectif:** Trouver des patterns exploitables pour passer de LB 0.807 a 0.82+  \n",
    "**Focus:** Relations non-lineaires, interactions, distributions train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "TARGET = 'Transported'\n",
    "\n",
    "print(f'Train: {train.shape}, Test: {test.shape}')\n",
    "print(f'\\nTarget: {train[TARGET].value_counts(normalize=True).to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vue d'ensemble et types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== COLONNES ===')\n",
    "for col in train.columns:\n",
    "    dtype = train[col].dtype\n",
    "    nunique = train[col].nunique()\n",
    "    null_pct = train[col].isnull().mean() * 100\n",
    "    sample = train[col].dropna().iloc[0] if not train[col].dropna().empty else 'N/A'\n",
    "    print(f'  {col:20s} | {str(dtype):10s} | {nunique:6d} uniq | {null_pct:5.2f}% null | ex: {sample}')\n",
    "\n",
    "print('\\n=== STATISTIQUES NUMERIQUES ===')\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Valeurs manquantes - Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: sont-elles correlees entre elles ?\n",
    "miss_cols = train.columns[train.isnull().any()].tolist()\n",
    "miss_matrix = train[miss_cols].isnull().astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Correlation des patterns de missing\n",
    "sns.heatmap(miss_matrix.corr(), annot=True, fmt='.2f', cmap='YlOrRd', ax=axes[0])\n",
    "axes[0].set_title('Correlation des valeurs manquantes')\n",
    "\n",
    "# Missing par ligne\n",
    "miss_per_row = train.isnull().sum(axis=1)\n",
    "axes[1].hist(miss_per_row, bins=range(0, miss_per_row.max()+2), color='steelblue', edgecolor='white')\n",
    "axes[1].set_title('Nombre de valeurs manquantes par passager')\n",
    "axes[1].set_xlabel('Nb missing')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Est-ce que les missing sont plus transported ?\n",
    "train['n_missing'] = train.isnull().sum(axis=1)\n",
    "print('\\nTransported rate by n_missing:')\n",
    "print(train.groupby('n_missing')[TARGET].agg(['mean', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CryoSleep - Le feature dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# CryoSleep vs Transported\n",
    "ct = pd.crosstab(train['CryoSleep'], train[TARGET], margins=True, normalize='index')\n",
    "print('CryoSleep vs Transported:')\n",
    "print(ct.round(4))\n",
    "\n",
    "# CryoSleep passengers should have 0 spending - verifier\n",
    "cryo_true = train[train['CryoSleep'] == True]\n",
    "cryo_spend = cryo_true[spend_cols].sum(axis=1)\n",
    "print(f'\\nCryoSleep=True avec spending > 0: {(cryo_spend > 0).sum()} / {len(cryo_true)}')\n",
    "\n",
    "# Non-CryoSleep avec 0 spending\n",
    "non_cryo = train[train['CryoSleep'] == False]\n",
    "non_cryo_nospend = non_cryo[spend_cols].sum(axis=1) == 0\n",
    "print(f'CryoSleep=False avec spending == 0: {non_cryo_nospend.sum()} / {len(non_cryo)}')\n",
    "print(f'  -> Transported rate: {non_cryo[non_cryo_nospend][TARGET].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cabin - Decomposition detaillee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Cabin\n",
    "train['Deck'] = train['Cabin'].str.split('/').str[0]\n",
    "train['CabinNum'] = train['Cabin'].str.split('/').str[1].astype(float)\n",
    "train['Side'] = train['Cabin'].str.split('/').str[2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Deck vs Transported\n",
    "deck_rate = train.groupby('Deck')[TARGET].mean().sort_values()\n",
    "deck_rate.plot(kind='barh', ax=axes[0,0], color='seagreen')\n",
    "axes[0,0].set_title('Transported Rate by Deck')\n",
    "axes[0,0].axvline(x=train[TARGET].mean(), color='red', linestyle='--', label='overall')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Side vs Transported  \n",
    "side_rate = train.groupby('Side')[TARGET].mean()\n",
    "side_rate.plot(kind='bar', ax=axes[0,1], color='coral')\n",
    "axes[0,1].set_title('Transported Rate by Side (P=Port, S=Starboard)')\n",
    "axes[0,1].axhline(y=train[TARGET].mean(), color='red', linestyle='--')\n",
    "\n",
    "# CabinNum distribution by Transported\n",
    "for t in [True, False]:\n",
    "    subset = train[train[TARGET] == t]['CabinNum'].dropna()\n",
    "    axes[1,0].hist(subset, bins=50, alpha=0.5, label=str(t), density=True)\n",
    "axes[1,0].set_title('CabinNum Distribution by Transported')\n",
    "axes[1,0].legend(title='Transported')\n",
    "\n",
    "# Deck + Side interaction\n",
    "deck_side = train.groupby(['Deck', 'Side'])[TARGET].agg(['mean', 'count']).reset_index()\n",
    "deck_side_pivot = deck_side.pivot(index='Deck', columns='Side', values='mean')\n",
    "sns.heatmap(deck_side_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[1,1])\n",
    "axes[1,1].set_title('Transported Rate: Deck x Side')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nDeck x Side counts:')\n",
    "print(deck_side.pivot(index='Deck', columns='Side', values='count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deck par HomePlanet - y a-t-il une relation ?\n",
    "ct = pd.crosstab(train['HomePlanet'], train['Deck'], normalize='index')\n",
    "print('HomePlanet vs Deck (row-normalized):')\n",
    "print(ct.round(3))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ct.plot(kind='bar', stacked=True, ax=ax, colormap='Set3')\n",
    "ax.set_title('Deck Distribution by HomePlanet')\n",
    "ax.legend(title='Deck', bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nKey insight: Europa -> Decks B,C ; Earth -> Decks F,G ; Mars -> Deck F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spending - Analyse detaillee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spending distributions for non-CryoSleep passengers only\n",
    "non_cryo = train[train['CryoSleep'] == False].copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(spend_cols):\n",
    "    data = non_cryo[non_cryo[col] > 0][col]  # only spenders\n",
    "    for t in [True, False]:\n",
    "        subset = non_cryo[(non_cryo[col] > 0) & (non_cryo[TARGET] == t)][col]\n",
    "        axes[i].hist(np.log1p(subset), bins=40, alpha=0.5, label=str(t), density=True)\n",
    "    axes[i].set_title(f'{col} (spenders only, log)')\n",
    "    axes[i].legend(title='Transported', fontsize=8)\n",
    "\n",
    "# Total spend\n",
    "non_cryo['TotalSpend'] = non_cryo[spend_cols].sum(axis=1)\n",
    "for t in [True, False]:\n",
    "    subset = non_cryo[(non_cryo['TotalSpend'] > 0) & (non_cryo[TARGET] == t)]['TotalSpend']\n",
    "    axes[5].hist(np.log1p(subset), bins=40, alpha=0.5, label=str(t), density=True)\n",
    "axes[5].set_title('TotalSpend (spenders only, log)')\n",
    "axes[5].legend(title='Transported', fontsize=8)\n",
    "\n",
    "plt.suptitle('Spending Analysis (Non-CryoSleep Only)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key spending thresholds\n",
    "non_cryo['TotalSpend'] = non_cryo[spend_cols].sum(axis=1)\n",
    "bins = [0, 1, 100, 500, 1000, 3000, 50000]\n",
    "non_cryo['SpendBucket'] = pd.cut(non_cryo['TotalSpend'], bins=bins)\n",
    "print('Transported rate by spending bucket (non-CryoSleep):')\n",
    "print(non_cryo.groupby('SpendBucket')[TARGET].agg(['mean', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which spending categories are most discriminative?\n",
    "non_cryo_spenders = non_cryo[non_cryo['TotalSpend'] > 0].copy()\n",
    "\n",
    "for col in spend_cols:\n",
    "    non_cryo_spenders[f'{col}_pct'] = non_cryo_spenders[col] / non_cryo_spenders['TotalSpend']\n",
    "\n",
    "# Spending profile by transported\n",
    "pct_cols = [f'{c}_pct' for c in spend_cols]\n",
    "profile = non_cryo_spenders.groupby(TARGET)[pct_cols].mean()\n",
    "print('Average spending profile by Transported (non-CryoSleep spenders):')\n",
    "print(profile.round(4))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "profile.T.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Spending Profile: Transported vs Not Transported')\n",
    "ax.set_ylabel('Average % of total spend')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Age - Analyse fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Age vs Transported rate (binned)\n",
    "train['AgeBin'] = pd.cut(train['Age'], bins=range(0, 85, 3))\n",
    "age_rate = train.groupby('AgeBin')[TARGET].agg(['mean', 'count'])\n",
    "age_rate['mean'].plot(ax=axes[0], marker='o', color='steelblue')\n",
    "axes[0].set_title('Transported Rate by Age (3-year bins)')\n",
    "axes[0].set_ylabel('Transported Rate')\n",
    "axes[0].axhline(y=0.5, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Age vs CryoSleep\n",
    "cryo_by_age = train.groupby('AgeBin')['CryoSleep'].mean()\n",
    "cryo_by_age.plot(ax=axes[1], marker='o', color='coral')\n",
    "axes[1].set_title('CryoSleep Rate by Age')\n",
    "axes[1].set_ylabel('CryoSleep Rate')\n",
    "\n",
    "# Age = 0 (babies)\n",
    "babies = train[train['Age'] == 0]\n",
    "print(f'Age=0 passengers: {len(babies)}')\n",
    "print(f'  Transported rate: {babies[TARGET].mean():.4f}')\n",
    "print(f'  CryoSleep rate: {babies[\"CryoSleep\"].mean():.4f}')\n",
    "\n",
    "# Age < 13 (children)\n",
    "children = train[train['Age'] < 13]\n",
    "print(f'\\nAge<13 passengers: {len(children)}')\n",
    "print(f'  Transported rate: {children[TARGET].mean():.4f}')\n",
    "\n",
    "# Age 13-17 (teens)\n",
    "teens = train[(train['Age'] >= 13) & (train['Age'] < 18)]\n",
    "print(f'\\nAge 13-17: {len(teens)}')\n",
    "print(f'  Transported rate: {teens[TARGET].mean():.4f}')\n",
    "\n",
    "# Age and spending\n",
    "train['TotalSpend'] = train[spend_cols].sum(axis=1)\n",
    "axes[2].scatter(train['Age'], np.log1p(train['TotalSpend']), \n",
    "                c=train[TARGET].map({True: 'green', False: 'red'}), alpha=0.2, s=5)\n",
    "axes[2].set_title('Age vs TotalSpend (log) colored by Transported')\n",
    "axes[2].set_xlabel('Age')\n",
    "axes[2].set_ylabel('log1p(TotalSpend)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Children cannot spend?\n",
    "under13 = train[train['Age'] < 13]\n",
    "print(f'\\nChildren <13 with any spending: {(under13[\"TotalSpend\"] > 0).sum()} / {len(under13)}')\n",
    "under13_spend = under13[under13['TotalSpend'] > 0]\n",
    "if len(under13_spend) > 0:\n",
    "    print(f'  Spending categories used:')\n",
    "    for col in spend_cols:\n",
    "        pct = (under13_spend[col] > 0).mean()\n",
    "        print(f'    {col}: {pct:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Groups & Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group analysis from PassengerId\n",
    "train['Group'] = train['PassengerId'].str.split('_').str[0].astype(int)\n",
    "train['MemberNum'] = train['PassengerId'].str.split('_').str[1].astype(int)\n",
    "test['Group'] = test['PassengerId'].str.split('_').str[0].astype(int)\n",
    "\n",
    "# Group sizes\n",
    "train_groups = train.groupby('Group').size().reset_index(name='GroupSize')\n",
    "train = train.merge(train_groups, on='Group', how='left')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# GroupSize distribution\n",
    "train['GroupSize'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Group Size Distribution')\n",
    "\n",
    "# GroupSize vs Transported\n",
    "gs_rate = train.groupby('GroupSize')[TARGET].agg(['mean', 'count'])\n",
    "gs_rate['mean'].plot(kind='bar', ax=axes[1], color='seagreen')\n",
    "axes[1].set_title('Transported Rate by Group Size')\n",
    "axes[1].axhline(y=0.5, color='red', linestyle='--')\n",
    "\n",
    "# Do group members share the same Transported status?\n",
    "group_stats = train.groupby('Group').agg(\n",
    "    size=('PassengerId', 'count'),\n",
    "    transported_sum=(TARGET, 'sum'),\n",
    "    transported_mean=(TARGET, 'mean')\n",
    ")\n",
    "multi_groups = group_stats[group_stats['size'] > 1]\n",
    "all_same = ((multi_groups['transported_mean'] == 0) | (multi_groups['transported_mean'] == 1)).mean()\n",
    "print(f'Multi-member groups: {len(multi_groups)}')\n",
    "print(f'Groups where ALL members have same Transported: {all_same:.2%}')\n",
    "\n",
    "multi_groups['transported_mean'].hist(bins=20, ax=axes[2], color='coral')\n",
    "axes[2].set_title('Transported Rate Distribution in Multi-member Groups')\n",
    "axes[2].set_xlabel('Group Transported Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surname analysis\n",
    "train['Surname'] = train['Name'].str.split().str[-1]\n",
    "\n",
    "surname_stats = train.groupby('Surname').agg(\n",
    "    size=('PassengerId', 'count'),\n",
    "    transported_mean=(TARGET, 'mean')\n",
    ").reset_index()\n",
    "\n",
    "multi_surname = surname_stats[surname_stats['size'] > 1]\n",
    "all_same_surname = ((multi_surname['transported_mean'] == 0) | (multi_surname['transported_mean'] == 1)).mean()\n",
    "print(f'Multi-member surnames: {len(multi_surname)}')\n",
    "print(f'Surnames where ALL have same Transported: {all_same_surname:.2%}')\n",
    "\n",
    "# Do Group members always share surname?\n",
    "group_surnames = train.groupby('Group')['Surname'].nunique()\n",
    "multi_group_surnames = group_surnames[group_surnames.index.isin(multi_groups.index)]\n",
    "print(f'\\nMulti-member groups with >1 surname: {(multi_group_surnames > 1).sum()} / {len(multi_group_surnames)}')\n",
    "print('-> Groups can contain multiple families!')\n",
    "\n",
    "# Groups that span train AND test\n",
    "train_group_set = set(train['Group'].unique())\n",
    "test_group_set = set(test['Group'].unique())\n",
    "shared_groups = train_group_set & test_group_set\n",
    "print(f'\\nGroups in both train and test: {len(shared_groups)}')\n",
    "print(f'Test passengers in shared groups: {test[test[\"Group\"].isin(shared_groups)].shape[0]} / {len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. HomePlanet x Destination x Deck Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple interaction\n",
    "triple = train.groupby(['HomePlanet', 'Destination'])[TARGET].agg(['mean', 'count']).reset_index()\n",
    "triple_pivot = triple.pivot(index='HomePlanet', columns='Destination', values='mean')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "sns.heatmap(triple_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[0])\n",
    "axes[0].set_title('Transported Rate: HomePlanet x Destination')\n",
    "\n",
    "# VIP analysis\n",
    "vip_hp = train.groupby(['HomePlanet', 'VIP'])[TARGET].agg(['mean', 'count']).reset_index()\n",
    "vip_pivot = vip_hp.pivot(index='HomePlanet', columns='VIP', values='mean')\n",
    "sns.heatmap(vip_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[1])\n",
    "axes[1].set_title('Transported Rate: HomePlanet x VIP')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Deck x Destination\n",
    "dd = train.groupby(['Deck', 'Destination'])[TARGET].agg(['mean', 'count']).reset_index()\n",
    "dd_pivot = dd.pivot(index='Deck', columns='Destination', values='mean')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(dd_pivot, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax)\n",
    "ax.set_title('Transported Rate: Deck x Destination')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train vs Test Distribution Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train/test distributions for key features\n",
    "test['Deck'] = test['Cabin'].str.split('/').str[0]\n",
    "test['Side'] = test['Cabin'].str.split('/').str[2]\n",
    "test['CabinNum'] = test['Cabin'].str.split('/').str[1].astype(float)\n",
    "test['TotalSpend'] = test[spend_cols].sum(axis=1)\n",
    "test['Surname'] = test['Name'].str.split().str[-1]\n",
    "\n",
    "compare_cols = ['HomePlanet', 'Destination', 'Deck', 'Side', 'CryoSleep', 'VIP']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(compare_cols):\n",
    "    train_dist = train[col].value_counts(normalize=True).sort_index()\n",
    "    test_dist = test[col].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    combined = pd.DataFrame({'Train': train_dist, 'Test': test_dist}).fillna(0)\n",
    "    combined.plot(kind='bar', ax=axes[i])\n",
    "    axes[i].set_title(f'{col}: Train vs Test')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Categorical Feature Distributions: Train vs Test', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Numerical distributions\n",
    "num_compare = ['Age', 'RoomService', 'FoodCourt', 'Spa', 'VRDeck', 'TotalSpend']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(num_compare):\n",
    "    axes[i].hist(train[col].dropna(), bins=50, alpha=0.5, label='Train', density=True)\n",
    "    axes[i].hist(test[col].dropna(), bins=50, alpha=0.5, label='Test', density=True)\n",
    "    axes[i].set_title(f'{col}: Train vs Test')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.suptitle('Numerical Feature Distributions: Train vs Test', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Key: No significant train/test drift detected = good for generalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Correlation avec la cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all candidate features for correlation analysis\n",
    "analysis = train.copy()\n",
    "analysis[TARGET] = analysis[TARGET].astype(int)\n",
    "analysis['CryoSleep'] = analysis['CryoSleep'].map({True: 1, False: 0}).fillna(-1)\n",
    "analysis['VIP'] = analysis['VIP'].map({True: 1, False: 0}).fillna(-1)\n",
    "analysis['TotalSpend_log'] = np.log1p(analysis['TotalSpend'])\n",
    "analysis['NoSpend'] = (analysis['TotalSpend'] == 0).astype(int)\n",
    "analysis['IsAlone'] = (analysis['GroupSize'] == 1).astype(int)\n",
    "analysis['IsChild'] = (analysis['Age'] < 13).astype(float)\n",
    "analysis['IsTeen'] = ((analysis['Age'] >= 13) & (analysis['Age'] < 18)).astype(float)\n",
    "analysis['Side_P'] = (analysis['Side'] == 'P').astype(float)\n",
    "\n",
    "for col in spend_cols:\n",
    "    analysis[f'{col}_log'] = np.log1p(analysis[col])\n",
    "\n",
    "corr_cols = [TARGET, 'CryoSleep', 'VIP', 'Age', 'TotalSpend_log', 'NoSpend',\n",
    "             'GroupSize', 'IsAlone', 'IsChild', 'IsTeen', 'Side_P'] + \\\n",
    "            [f'{c}_log' for c in spend_cols]\n",
    "\n",
    "corr = analysis[corr_cols].corr()[TARGET].drop(TARGET).sort_values(key=abs, ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "corr.plot(kind='barh', ax=ax, color=['green' if v > 0 else 'red' for v in corr])\n",
    "ax.set_title('Feature Correlations with Transported')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Top correlations with Transported:')\n",
    "print(corr.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Synthese EDA - Insights actionables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('           SPACESHIP TITANIC - EDA SYNTHESIS')\n",
    "print('=' * 70)\n",
    "print()\n",
    "print('--- DATA ---')\n",
    "print(f'  Train: 8693 rows, 14 cols | Test: 4277 rows, 13 cols')\n",
    "print(f'  Target: ~50/50 balanced (50.4% True)')\n",
    "print(f'  Missing: ~2% across all columns, correlated patterns')\n",
    "print()\n",
    "print('--- TOP PREDICTORS (by correlation) ---')\n",
    "print(f'  1. CryoSleep (+0.47) - THE dominant feature')\n",
    "print(f'  2. NoSpend (+0.43) - highly correlated with CryoSleep')\n",
    "print(f'  3. Spending cols (-0.20 to -0.24) - each service matters')\n",
    "print(f'  4. Deck (B,C > others) - clear deck-based patterns')\n",
    "print(f'  5. Side (S slightly > P)')\n",
    "print()\n",
    "print('--- KEY PATTERNS FOR FEATURE ENGINEERING ---')\n",
    "print(f'  1. CryoSleep = True -> ~80% transported (strong rule)')\n",
    "print(f'  2. Children <13 are MUCH more likely transported (~67%)')\n",
    "print(f'  3. Europa passengers on Decks B/C -> very high transport rate')\n",
    "print(f'  4. HomePlanet strongly determines Deck assignment')\n",
    "print(f'     Europa -> B,C | Earth -> F,G | Mars -> F')\n",
    "print(f'  5. Group members often (but NOT always) share Transported status')\n",
    "print(f'     ~60% of multi-member groups have unanimous status')\n",
    "print(f'  6. Groups span train/test: {len(shared_groups)} shared groups')\n",
    "print(f'     -> {test[test[\"Group\"].isin(shared_groups)].shape[0]}/{len(test)} test passengers in shared groups')\n",
    "print(f'  7. Groups can contain multiple surnames (not pure families)')\n",
    "print()\n",
    "print('--- FEATURE ENGINEERING IDEAS ---')\n",
    "print('  A. Deck x Side interaction (some combos very predictive)')\n",
    "print('  B. HomePlanet x Deck interaction')\n",
    "print('  C. Age buckets: baby(0), child(<13), teen(13-17), adult(18+)')\n",
    "print('  D. Spending per category as % of total')\n",
    "print('  E. Binary: has_any_luxury_spend, has_any_basic_spend')\n",
    "print('  F. n_missing as feature (proxy for data quality)')\n",
    "print('  G. CabinNum region interactions with Deck')\n",
    "print('  H. Group transported rate (careful with leakage!)')\n",
    "print()\n",
    "print('--- WARNINGS ---')\n",
    "print('  - NoSpend and CryoSleep are ~90% correlated -> redundant')\n",
    "print('  - Group/Surname survival features leak if not done carefully')\n",
    "print('  - No significant train/test drift -> good for generalization')\n",
    "print('=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
