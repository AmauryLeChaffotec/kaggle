{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - 0.80861 avec le Group Survival Trick\n",
    "\n",
    "**Approche :** Les passagers du Titanic ne voyageaient pas seuls. En exploitant les liens entre passagers (meme billet, meme famille), on peut propager l'information de survie connue du train vers le test.\n",
    "\n",
    "**Pipeline :**\n",
    "1. Feature Engineering classique (Title, FamilySize, etc.)\n",
    "2. Group Survival Trick (ticket groups + family groups)\n",
    "3. Ensemble de 6 modeles conservateurs (anti-overfitting sur 891 lignes)\n",
    "4. Simple Average (pas d'optimisation de poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "np.random.seed(SEED)\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "print(f'Train: {train.shape}, Test: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA rapide\n",
    "\n",
    "Les deux facteurs dominants sont le sexe et la classe. Leur interaction montre ou se trouvent les cas faciles et les cas difficiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = train.pivot_table(values='Survived', index='Sex', columns='Pclass', aggfunc='mean')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "sns.heatmap(pivot, annot=True, fmt='.1%', cmap='RdYlGn', ax=ax,\n",
    "            xticklabels=['1ere', '2eme', '3eme'])\n",
    "ax.set_title('Taux de survie : Sexe x Classe')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Les cas \"faciles\" : femmes 1ere/2eme (~95%), hommes 2eme/3eme (~14%)\n",
    "# Les cas \"difficiles\" : femmes 3eme (50%), hommes 1ere (37%)\n",
    "# -> C'est sur ces cas que le Group Survival Trick fait la difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Toutes les imputations et statistiques sont calculees sur le train uniquement pour eviter le data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title extraction\n",
    "for df in [train, test]:\n",
    "    df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "    title_map = {\n",
    "        'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "        'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "        'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Countess': 'Rare',\n",
    "        'Lady': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Dona': 'Rare',\n",
    "        'Jonkheer': 'Rare', 'Capt': 'Rare'\n",
    "    }\n",
    "    df['Title'] = df['Title'].map(title_map).fillna('Rare')\n",
    "\n",
    "# Imputation Age par mediane du titre (train only)\n",
    "age_by_title = train.groupby('Title')['Age'].median()\n",
    "for df in [train, test]:\n",
    "    for title in df['Title'].unique():\n",
    "        mask = (df['Age'].isnull()) & (df['Title'] == title)\n",
    "        df.loc[mask, 'Age'] = age_by_title.get(title, train['Age'].median())\n",
    "\n",
    "# Imputation Embarked et Fare (train only)\n",
    "embarked_mode = train['Embarked'].mode()[0]\n",
    "fare_by_class = train.groupby('Pclass')['Fare'].median()\n",
    "for df in [train, test]:\n",
    "    df['Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "    for pclass in [1, 2, 3]:\n",
    "        mask = (df['Fare'].isnull()) & (df['Pclass'] == pclass)\n",
    "        df.loc[mask, 'Fare'] = fare_by_class[pclass]\n",
    "\n",
    "# Features de base\n",
    "for df in [train, test]:\n",
    "    df['Sex_enc'] = (df['Sex'] == 'male').astype(int)\n",
    "    df['Title_enc'] = df['Title'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Rare': 4}).fillna(4).astype(int)\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['IsChild'] = (df['Age'] <= 12).astype(int)\n",
    "    df['Age_Pclass'] = df['Age'] * df['Pclass']\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Embarked_enc'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2}).fillna(2).astype(int)\n",
    "    df['Surname'] = df['Name'].str.split(',').str[0]\n",
    "\n",
    "print('14 features de base OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Survival Trick\n",
    "\n",
    "L'idee : les familles et groupes (meme billet) tendent a survivre ou mourir ensemble. Si je connais la survie des autres membres du groupe dans le train, ca me donne un signal fort pour predire ceux du test.\n",
    "\n",
    "Trois niveaux de signal :\n",
    "1. **Ticket Group** : passagers partageant le meme numero de billet\n",
    "2. **Family Group** : meme nom de famille + meme taille de famille\n",
    "3. **Sex-specific** : taux de survie des femmes/enfants vs hommes dans chaque groupe de billet\n",
    "\n",
    "Pour le train, on utilise le **leave-one-out** (taux du groupe sans le passager lui-meme) pour eviter de tricher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ticket Group Survival Rate ---\n",
    "# Leave-one-out pour le train\n",
    "train_ticket_sum = train.groupby('Ticket')['Survived'].transform('sum')\n",
    "train_ticket_cnt = train.groupby('Ticket')['Survived'].transform('count')\n",
    "train['TicketGroupSurvRate'] = np.where(\n",
    "    train_ticket_cnt > 1,\n",
    "    (train_ticket_sum - train['Survived']) / (train_ticket_cnt - 1),\n",
    "    -1\n",
    ")\n",
    "\n",
    "# Pour le test : moyenne du groupe dans le train\n",
    "ticket_surv_map = train.groupby('Ticket')['Survived'].mean()\n",
    "test['TicketGroupSurvRate'] = test['Ticket'].map(ticket_surv_map).fillna(-1)\n",
    "\n",
    "# Taille du groupe de billet (info structurelle)\n",
    "combined_ticket_size = pd.concat([train['Ticket'], test['Ticket']]).value_counts()\n",
    "for df in [train, test]:\n",
    "    df['TicketGroupSize'] = df['Ticket'].map(combined_ticket_size)\n",
    "\n",
    "# --- Family Group Survival Rate ---\n",
    "for df in [train, test]:\n",
    "    df['FamilyGroup'] = df['Surname'] + '_' + df['FamilySize'].astype(str)\n",
    "\n",
    "family_surv_map = train.groupby('FamilyGroup')['Survived'].mean()\n",
    "train_fg_sum = train.groupby('FamilyGroup')['Survived'].transform('sum')\n",
    "train_fg_cnt = train.groupby('FamilyGroup')['Survived'].transform('count')\n",
    "train['FamilyGroupSurvRate'] = np.where(\n",
    "    train_fg_cnt > 1,\n",
    "    (train_fg_sum - train['Survived']) / (train_fg_cnt - 1),\n",
    "    -1\n",
    ")\n",
    "test['FamilyGroupSurvRate'] = test['FamilyGroup'].map(family_surv_map).fillna(-1)\n",
    "\n",
    "print(f'Ticket group info: train {(train[\"TicketGroupSurvRate\"]!=-1).sum()}/{len(train)}, '\n",
    "      f'test {(test[\"TicketGroupSurvRate\"]!=-1).sum()}/{len(test)}')\n",
    "print(f'Family group info: train {(train[\"FamilyGroupSurvRate\"]!=-1).sum()}/{len(train)}, '\n",
    "      f'test {(test[\"FamilyGroupSurvRate\"]!=-1).sum()}/{len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sex-specific group survival ---\n",
    "# Les femmes/enfants d'un groupe survivent ensemble,\n",
    "# les hommes d'un groupe meurent ensemble.\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['IsWomanChild'] = ((df['Sex'] == 'female') | (df['Age'] <= 12)).astype(int)\n",
    "\n",
    "wc_train = train[train['IsWomanChild'] == 1]\n",
    "men_train = train[train['IsWomanChild'] == 0]\n",
    "\n",
    "wc_ticket_surv = wc_train.groupby('Ticket')['Survived'].mean()\n",
    "men_ticket_surv = men_train.groupby('Ticket')['Survived'].mean()\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['TicketWCSurvRate'] = df['Ticket'].map(wc_ticket_surv).fillna(-1)\n",
    "    df['TicketMenSurvRate'] = df['Ticket'].map(men_ticket_surv).fillna(-1)\n",
    "\n",
    "# Leave-one-out pour le train\n",
    "for idx in train.index:\n",
    "    ticket = train.loc[idx, 'Ticket']\n",
    "    is_wc = train.loc[idx, 'IsWomanChild']\n",
    "    if is_wc == 1:\n",
    "        group = wc_train[(wc_train['Ticket'] == ticket) & (wc_train.index != idx)]\n",
    "        train.loc[idx, 'TicketWCSurvRate'] = group['Survived'].mean() if len(group) > 0 else -1\n",
    "    else:\n",
    "        group = men_train[(men_train['Ticket'] == ticket) & (men_train.index != idx)]\n",
    "        train.loc[idx, 'TicketMenSurvRate'] = group['Survived'].mean() if len(group) > 0 else -1\n",
    "\n",
    "# Signal combine : meilleure source disponible pour chaque passager\n",
    "for df in [train, test]:\n",
    "    df['GroupSurvSignal'] = np.where(\n",
    "        df['IsWomanChild'] == 1,\n",
    "        np.where(df['TicketWCSurvRate'] >= 0, df['TicketWCSurvRate'],\n",
    "                 np.where(df['FamilyGroupSurvRate'] >= 0, df['FamilyGroupSurvRate'],\n",
    "                          np.where(df['TicketGroupSurvRate'] >= 0, df['TicketGroupSurvRate'], -1))),\n",
    "        np.where(df['TicketMenSurvRate'] >= 0, df['TicketMenSurvRate'],\n",
    "                 np.where(df['FamilyGroupSurvRate'] >= 0, df['FamilyGroupSurvRate'],\n",
    "                          np.where(df['TicketGroupSurvRate'] >= 0, df['TicketGroupSurvRate'], -1)))\n",
    "    )\n",
    "    df['HasGroupInfo'] = (df['GroupSurvSignal'] >= 0).astype(int)\n",
    "\n",
    "# Verification : le signal est-il discriminant ?\n",
    "has = train[train['HasGroupInfo'] == 1]\n",
    "print(f'\\nSignal >= 0.5 -> survie = {has[has[\"GroupSurvSignal\"]>=0.5][\"Survived\"].mean():.0%} '\n",
    "      f'(n={len(has[has[\"GroupSurvSignal\"]>=0.5])})')\n",
    "print(f'Signal <  0.5 -> survie = {has[has[\"GroupSurvSignal\"]<0.5][\"Survived\"].mean():.0%} '\n",
    "      f'(n={len(has[has[\"GroupSurvSignal\"]<0.5])})')\n",
    "print(f'Pas de signal -> survie = {train[train[\"HasGroupInfo\"]==0][\"Survived\"].mean():.0%} '\n",
    "      f'(n={len(train[train[\"HasGroupInfo\"]==0])})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Base\n",
    "    'Pclass', 'Sex_enc', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "    'Title_enc', 'FamilySize', 'IsAlone', 'HasCabin', 'IsChild',\n",
    "    'Age_Pclass', 'LogFare', 'Embarked_enc',\n",
    "    # Group Survival\n",
    "    'TicketGroupSurvRate', 'TicketGroupSize', 'FamilyGroupSurvRate',\n",
    "    'TicketWCSurvRate', 'TicketMenSurvRate',\n",
    "    'GroupSurvSignal', 'HasGroupInfo', 'IsWomanChild',\n",
    "]\n",
    "\n",
    "X = train[features].values\n",
    "y = train['Survived'].values.astype(int)\n",
    "X_test = test[features].values\n",
    "test_ids = test['PassengerId'].values\n",
    "\n",
    "print(f'{len(features)} features (14 base + 8 group), 0 NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "6 modeles avec des parametres tres conservateurs (forte regularisation, pas de tuning Optuna) pour eviter l'overfitting sur 891 lignes. 10-Fold CV pour une estimation stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results = {}\n",
    "\n",
    "def train_model(name, model, X_tr, X_te, fit_kw=None):\n",
    "    oof = np.zeros(len(y))\n",
    "    test_preds = np.zeros(len(test_ids))\n",
    "    scores = []\n",
    "    for ti, vi in kf.split(X_tr, y):\n",
    "        if fit_kw:\n",
    "            model.fit(X_tr[ti], y[ti], **{k: v(X_tr, y, vi) if callable(v) else v for k, v in fit_kw.items()})\n",
    "        else:\n",
    "            m = type(model)(**model.get_params()) if hasattr(model, 'get_params') else model\n",
    "            m.fit(X_tr[ti], y[ti])\n",
    "            oof[vi] = m.predict_proba(X_tr[vi])[:, 1]\n",
    "            test_preds += m.predict_proba(X_te)[:, 1] / N_FOLDS\n",
    "            scores.append(accuracy_score(y[vi], m.predict(X_tr[vi])))\n",
    "    acc = np.mean(scores)\n",
    "    print(f'{name:4s}: {acc:.5f} +/- {np.std(scores):.5f}')\n",
    "    results[name] = {'oof': oof, 'test': test_preds, 'acc': acc}\n",
    "\n",
    "# LR, RF, SVM\n",
    "for name, model, Xi, Xti in [\n",
    "    ('LR', LogisticRegression(C=0.5, max_iter=1000, random_state=SEED), X_scaled, X_test_scaled),\n",
    "    ('RF', RandomForestClassifier(n_estimators=300, max_depth=5, min_samples_split=10,\n",
    "           min_samples_leaf=5, max_features='sqrt', random_state=SEED, n_jobs=-1), X, X_test),\n",
    "    ('SVM', SVC(C=0.8, kernel='rbf', gamma='scale', probability=True, random_state=SEED), X_scaled, X_test_scaled),\n",
    "]:\n",
    "    oof = np.zeros(len(y)); tp = np.zeros(len(test_ids)); ss = []\n",
    "    for ti, vi in kf.split(Xi, y):\n",
    "        m = type(model)(**model.get_params())\n",
    "        m.fit(Xi[ti], y[ti])\n",
    "        oof[vi] = m.predict_proba(Xi[vi])[:, 1]\n",
    "        tp += m.predict_proba(Xti)[:, 1] / N_FOLDS\n",
    "        ss.append(accuracy_score(y[vi], m.predict(Xi[vi])))\n",
    "    print(f'{name:4s}: {np.mean(ss):.5f} +/- {np.std(ss):.5f}')\n",
    "    results[name] = {'oof': oof, 'test': tp, 'acc': np.mean(ss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM - conservateur\n",
    "lgb_params = {\n",
    "    'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt',\n",
    "    'num_leaves': 15, 'learning_rate': 0.05, 'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7, 'bagging_freq': 5, 'min_child_samples': 30,\n",
    "    'reg_alpha': 1.0, 'reg_lambda': 5.0, 'n_estimators': 300,\n",
    "    'verbose': -1, 'random_state': SEED,\n",
    "}\n",
    "oof = np.zeros(len(y)); tp = np.zeros(len(test_ids)); ss = []\n",
    "for ti, vi in kf.split(X, y):\n",
    "    m = lgb.LGBMClassifier(**lgb_params)\n",
    "    m.fit(X[ti], y[ti], eval_set=[(X[vi], y[vi])],\n",
    "          callbacks=[lgb.early_stopping(30, verbose=False), lgb.log_evaluation(0)])\n",
    "    oof[vi] = m.predict_proba(X[vi])[:, 1]\n",
    "    tp += m.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    ss.append(accuracy_score(y[vi], m.predict(X[vi])))\n",
    "print(f'LGB : {np.mean(ss):.5f} +/- {np.std(ss):.5f}')\n",
    "results['LGB'] = {'oof': oof, 'test': tp, 'acc': np.mean(ss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost - conservateur\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'logloss',\n",
    "    'max_depth': 3, 'learning_rate': 0.05, 'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7, 'min_child_weight': 10,\n",
    "    'reg_alpha': 1.0, 'reg_lambda': 5.0, 'gamma': 0.5,\n",
    "    'n_estimators': 300, 'random_state': SEED, 'verbosity': 0,\n",
    "}\n",
    "oof = np.zeros(len(y)); tp = np.zeros(len(test_ids)); ss = []\n",
    "for ti, vi in kf.split(X, y):\n",
    "    m = xgb.XGBClassifier(**xgb_params)\n",
    "    m.fit(X[ti], y[ti], eval_set=[(X[vi], y[vi])], verbose=False)\n",
    "    oof[vi] = m.predict_proba(X[vi])[:, 1]\n",
    "    tp += m.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    ss.append(accuracy_score(y[vi], m.predict(X[vi])))\n",
    "print(f'XGB : {np.mean(ss):.5f} +/- {np.std(ss):.5f}')\n",
    "results['XGB'] = {'oof': oof, 'test': tp, 'acc': np.mean(ss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost - conservateur\n",
    "oof = np.zeros(len(y)); tp = np.zeros(len(test_ids)); ss = []\n",
    "for ti, vi in kf.split(X, y):\n",
    "    m = CatBoostClassifier(iterations=300, depth=4, learning_rate=0.05,\n",
    "        l2_leaf_reg=5.0, random_seed=SEED, verbose=0, early_stopping_rounds=30)\n",
    "    m.fit(X[ti], y[ti], eval_set=(X[vi], y[vi]), verbose=0)\n",
    "    oof[vi] = m.predict_proba(X[vi])[:, 1]\n",
    "    tp += m.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    ss.append(accuracy_score(y[vi], m.predict(X[vi])))\n",
    "print(f'CB  : {np.mean(ss):.5f} +/- {np.std(ss):.5f}')\n",
    "results['CB'] = {'oof': oof, 'test': tp, 'acc': np.mean(ss)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_features = ['TicketGroupSurvRate', 'TicketGroupSize', 'FamilyGroupSurvRate',\n",
    "                  'TicketWCSurvRate', 'TicketMenSurvRate', 'GroupSurvSignal',\n",
    "                  'HasGroupInfo', 'IsWomanChild']\n",
    "\n",
    "cb_full = CatBoostClassifier(iterations=300, depth=4, learning_rate=0.05,\n",
    "    l2_leaf_reg=5.0, random_seed=SEED, verbose=0)\n",
    "cb_full.fit(X, y)\n",
    "\n",
    "imp = pd.DataFrame({'feature': features, 'importance': cb_full.feature_importances_})\n",
    "imp = imp.sort_values('importance', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "colors = ['#e74c3c' if f in group_features else '#3498db' for f in imp['feature']]\n",
    "ax.barh(imp['feature'], imp['importance'], color=colors)\n",
    "ax.set_title('Feature Importance (bleu=base, rouge=group survival)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "group_pct = imp[imp['feature'].isin(group_features)]['importance'].sum() / imp['importance'].sum()\n",
    "print(f'Les group features representent {group_pct:.0%} de l importance totale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble & Soumission\n",
    "\n",
    "Simple average des 6 modeles. Pas d'optimisation de poids (overfit sur 891 lignes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oof = np.column_stack([results[m]['oof'] for m in results])\n",
    "all_test = np.column_stack([results[m]['test'] for m in results])\n",
    "\n",
    "ensemble_acc = accuracy_score(y, (all_oof.mean(axis=1) > 0.5).astype(int))\n",
    "print(f'Ensemble CV: {ensemble_acc:.5f}')\n",
    "for name in sorted(results, key=lambda x: results[x]['acc'], reverse=True):\n",
    "    print(f'  {name}: {results[name][\"acc\"]:.5f}')\n",
    "\n",
    "# Soumission\n",
    "final_preds = (all_test.mean(axis=1) > 0.5).astype(int)\n",
    "submission = pd.DataFrame({'PassengerId': test_ids.astype(int), 'Survived': final_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f'\\nsubmission.csv: {submission.shape}, survival rate = {submission.Survived.mean():.1%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
