{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - V8 (V5 + Surgical Features + Diverse Ensemble)\n",
    "\n",
    "**Base:** V5 = best LB 0.80874 (V2 features + TE bayésien, params manuels V2)\n",
    "\n",
    "**V8 additions:**\n",
    "1. **Cabin spatial features** — CabinNum is spatial position, nearby passengers share fate\n",
    "2. **Group spending patterns** — max_spend_in_group, spend_rank_in_group\n",
    "3. **Strong interactions** — CryoSleep×Age, Deck×Destination\n",
    "4. **Diverse ensemble** — Add ExtraTrees + RandomForest to break >98% GBDT correlation\n",
    "\n",
    "| V | CV | LB | Gap | Features |\n",
    "|---|------|--------|------|----------|\n",
    "| V2 | 0.81410 | 0.80710 | 0.0070 | 29 |\n",
    "| V5 | 0.81767 | 0.80874 | 0.0089 | 32 |\n",
    "| V8 | ? | ? | ? | ~38 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "TARGET = 'Transported'\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything()\n",
    "print('V8 Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test[TARGET] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "print(f'Combined: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5 Base Features (identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V2 Feature Engineering (identical to V5) ===\n",
    "df['_Group'] = df['PassengerId'].str.split('_').str[0].astype(int)\n",
    "df['GroupSize'] = df.groupby('_Group')['PassengerId'].transform('count')\n",
    "df['IsAlone'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "df['CabinNum'] = df['Cabin'].str.split('/').str[1].astype(float)\n",
    "df['Side'] = df['Cabin'].str.split('/').str[2]\n",
    "df['CabinRegion'] = (df['CabinNum'] // 100).astype(float)\n",
    "\n",
    "df['Surname'] = df['Name'].str.split().str[-1]\n",
    "df['FamilySize'] = df.groupby('Surname')['PassengerId'].transform('count')\n",
    "df.loc[df['Surname'].isna(), 'FamilySize'] = 1\n",
    "\n",
    "df['CryoSleep'] = df['CryoSleep'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df['VIP'] = df['VIP'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "\n",
    "# V2 Imputation\n",
    "for col in spend_cols:\n",
    "    mask = (df['CryoSleep'] == 1) & (df[col].isna())\n",
    "    df.loc[mask, col] = 0\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) == 0)\n",
    "df.loc[mask, 'CryoSleep'] = 1\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) > 0)\n",
    "df.loc[mask, 'CryoSleep'] = 0\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# V2 Spending\n",
    "df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "df['TotalSpend_log'] = np.log1p(df['TotalSpend'])\n",
    "df['NoSpend'] = (df['TotalSpend'] == 0).astype(int)\n",
    "df['NumServicesUsed'] = (df[spend_cols] > 0).sum(axis=1)\n",
    "for col in spend_cols:\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "df['LuxurySpend'] = np.log1p(df['Spa'] + df['VRDeck'] + df['RoomService'])\n",
    "df['BasicSpend'] = np.log1p(df['FoodCourt'] + df['ShoppingMall'])\n",
    "\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0,5,12,18,30,50,80], labels=[0,1,2,3,4,5]).astype(float)\n",
    "df['IsChild'] = (df['Age'] < 18).astype(float)\n",
    "df['CryoSleep_NoSpend'] = ((df['CryoSleep'] == 1) & (df['TotalSpend'] == 0)).astype(int)\n",
    "\n",
    "df['GroupSpend_mean'] = df.groupby('_Group')['TotalSpend'].transform('mean')\n",
    "df['GroupSpend_mean_log'] = np.log1p(df['GroupSpend_mean'])\n",
    "\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_freq'] = df[col].map(freq)\n",
    "\n",
    "print('V2 base features done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V5 Target Encoding (identical) ===\n",
    "te_cols = ['HomePlanet', 'Destination', 'Deck']\n",
    "SMOOTHING = 20\n",
    "\n",
    "train_idx = df[df['is_train'] == 1].index\n",
    "test_idx = df[df['is_train'] == 0].index\n",
    "\n",
    "y_for_te = df.loc[train_idx, TARGET].map({True: 1.0, False: 0.0, 1: 1.0, 0: 0.0}).astype(float)\n",
    "df.loc[train_idx, '_target_float'] = y_for_te.values\n",
    "global_mean = float(y_for_te.mean())\n",
    "\n",
    "kf_te = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for col in te_cols:\n",
    "    col_te = f'{col}_te'\n",
    "    df[col_te] = global_mean\n",
    "    \n",
    "    for fold_train, fold_val in kf_te.split(train_idx, y_for_te):\n",
    "        fold_train_idx = train_idx[fold_train]\n",
    "        fold_val_idx = train_idx[fold_val]\n",
    "        stats = df.loc[fold_train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "        stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "        mapped = df.loc[fold_val_idx, col].map(stats['te']).fillna(global_mean)\n",
    "        df.loc[fold_val_idx, col_te] = mapped.values\n",
    "    \n",
    "    stats = df.loc[train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "    stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "    mapped = df.loc[test_idx, col].map(stats['te']).fillna(global_mean)\n",
    "    df.loc[test_idx, col_te] = mapped.values\n",
    "\n",
    "df.drop('_target_float', axis=1, inplace=True)\n",
    "print('V5 TE done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V8 New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NEW 1: Cabin spatial features ===\n",
    "# CabinNum is position on ship — nearby passengers share fate\n",
    "# Finer spatial region (CabinRegion = //100, this = //50 for more resolution)\n",
    "df['CabinRegion_fine'] = (df['CabinNum'] // 50).astype(float)\n",
    "\n",
    "# Group cabin spatial stats (how spread out is the group on the ship?)\n",
    "df['GroupCabinNum_mean'] = df.groupby('_Group')['CabinNum'].transform('mean')\n",
    "df['CabinNum_diff_group'] = df['CabinNum'] - df['GroupCabinNum_mean']\n",
    "\n",
    "print('Cabin spatial features done.')\n",
    "print(f\"  CabinRegion_fine: {df['CabinRegion_fine'].nunique()} unique values\")\n",
    "print(f\"  CabinNum_diff_group: mean={df['CabinNum_diff_group'].mean():.2f}, std={df['CabinNum_diff_group'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NEW 2: Group spending patterns ===\n",
    "# Max spender in group (computed on train+test = safe)\n",
    "df['GroupSpend_max'] = df.groupby('_Group')['TotalSpend'].transform('max')\n",
    "df['GroupSpend_max_log'] = np.log1p(df['GroupSpend_max'])\n",
    "\n",
    "# Spend rank within group (pct rank: 0=lowest, 1=highest)\n",
    "df['SpendRank_in_group'] = df.groupby('_Group')['TotalSpend'].rank(pct=True)\n",
    "# For solo passengers, rank is always 1.0 — make it 0.5 (neutral)\n",
    "df.loc[df['GroupSize'] == 1, 'SpendRank_in_group'] = 0.5\n",
    "\n",
    "print('Group spending patterns done.')\n",
    "print(f\"  SpendRank_in_group: mean={df['SpendRank_in_group'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NEW 3: Strong interactions ===\n",
    "# CryoSleep × Age: cryo children behave differently than cryo adults\n",
    "df['Cryo_x_Age'] = df['CryoSleep'] * df['Age']\n",
    "df['Cryo_x_IsChild'] = df['CryoSleep'] * df['IsChild']\n",
    "\n",
    "# Deck × Destination: frequency encode (low risk, computed on train+test)\n",
    "df['DeckDest'] = df['Deck'] + '_' + df['Destination']\n",
    "freq = df['DeckDest'].value_counts(normalize=True)\n",
    "df['DeckDest_freq'] = df['DeckDest'].map(freq)\n",
    "\n",
    "print('Interactions done.')\n",
    "print(f\"  DeckDest unique: {df['DeckDest'].nunique()} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEFINE FEATURES ===\n",
    "drop_cols = [\n",
    "    'PassengerId', 'Name', 'Cabin', 'Surname', 'is_train', TARGET,\n",
    "    'HomePlanet', 'Destination', 'Deck', 'Side', 'DeckDest',\n",
    "    '_Group', 'CabinNum',\n",
    "    'TotalSpend', 'GroupSpend_mean', 'GroupSpend_max', 'GroupCabinNum_mean',\n",
    "] + spend_cols\n",
    "\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f'V8 features: {len(features)} (V5: 32 + 7 new)')\n",
    "print()\n",
    "\n",
    "v5_features = [\n",
    "    'Age', 'AgeGroup', 'BasicSpend', 'CabinRegion', 'CryoSleep',\n",
    "    'CryoSleep_NoSpend', 'Deck_freq', 'Deck_le', 'Deck_te',\n",
    "    'Destination_freq', 'Destination_le', 'Destination_te', 'FamilySize',\n",
    "    'FoodCourt_log', 'GroupSize', 'GroupSpend_mean_log', 'HomePlanet_freq',\n",
    "    'HomePlanet_le', 'HomePlanet_te', 'IsAlone', 'IsChild', 'LuxurySpend',\n",
    "    'NoSpend', 'NumServicesUsed', 'RoomService_log', 'ShoppingMall_log',\n",
    "    'Side_freq', 'Side_le', 'Spa_log', 'TotalSpend_log', 'VIP', 'VRDeck_log'\n",
    "]\n",
    "\n",
    "for i, f in enumerate(sorted(features)):\n",
    "    marker = ' *** NEW' if f not in v5_features else ''\n",
    "    print(f'  {i+1:2d}. {f}{marker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[TARGET].astype(int).values\n",
    "X_test = test_df[features].values\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}')\n",
    "print(f'Target mean: {np.mean(y):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 0: GBDT Models (V2 manual params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# === LightGBM (V2 params) ===\n",
    "lgb_params = {\n",
    "    'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt',\n",
    "    'num_leaves': 20, 'learning_rate': 0.03, 'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7, 'bagging_freq': 5, 'min_child_samples': 30,\n",
    "    'reg_alpha': 0.5, 'reg_lambda': 2.0, 'max_depth': 5,\n",
    "    'n_estimators': 5000, 'verbose': -1, 'n_jobs': -1, 'random_state': SEED,\n",
    "}\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "fi_lgb = np.zeros(len(features))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(X[tr_idx], y[tr_idx], eval_set=[(X[val_idx], y[val_idx])],\n",
    "              callbacks=[lgb.early_stopping(200), lgb.log_evaluation(0)])\n",
    "    oof_lgb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "    test_lgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    fi_lgb += model.feature_importances_ / N_FOLDS\n",
    "\n",
    "lgb_acc = accuracy_score(y, (oof_lgb > 0.5).astype(int))\n",
    "print(f'LightGBM CV: {lgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === XGBoost (V2 params) ===\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'logloss',\n",
    "    'max_depth': 4, 'learning_rate': 0.03, 'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7, 'min_child_weight': 10,\n",
    "    'reg_alpha': 0.5, 'reg_lambda': 2.0, 'gamma': 0.1,\n",
    "    'n_estimators': 5000, 'early_stopping_rounds': 200,\n",
    "    'tree_method': 'hist', 'random_state': SEED, 'verbosity': 0,\n",
    "}\n",
    "\n",
    "oof_xgb = np.zeros(len(X))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X[tr_idx], y[tr_idx], eval_set=[(X[val_idx], y[val_idx])], verbose=0)\n",
    "    oof_xgb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "    test_xgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "\n",
    "xgb_acc = accuracy_score(y, (oof_xgb > 0.5).astype(int))\n",
    "print(f'XGBoost CV:  {xgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CatBoost (V2 params) ===\n",
    "oof_cb = np.zeros(len(X))\n",
    "test_cb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=5000, learning_rate=0.03, depth=4, l2_leaf_reg=5.0,\n",
    "        subsample=0.7, colsample_bylevel=0.7, min_data_in_leaf=30,\n",
    "        random_seed=SEED, verbose=0, early_stopping_rounds=200, task_type='CPU',\n",
    "    )\n",
    "    model.fit(X[tr_idx], y[tr_idx], eval_set=(X[val_idx], y[val_idx]))\n",
    "    oof_cb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "    test_cb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "\n",
    "cb_acc = accuracy_score(y, (oof_cb > 0.5).astype(int))\n",
    "print(f'CatBoost CV: {cb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 0: Non-GBDT Models (diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for sklearn models\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === ExtraTrees ===\n",
    "oof_et = np.zeros(len(X))\n",
    "test_et = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_scaled, y)):\n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=1000, max_depth=12, min_samples_leaf=10,\n",
    "        max_features=0.7, random_state=SEED, n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_scaled[tr_idx], y[tr_idx])\n",
    "    oof_et[val_idx] = model.predict_proba(X_scaled[val_idx])[:, 1]\n",
    "    test_et += model.predict_proba(X_test_scaled)[:, 1] / N_FOLDS\n",
    "\n",
    "et_acc = accuracy_score(y, (oof_et > 0.5).astype(int))\n",
    "print(f'ExtraTrees CV: {et_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RandomForest ===\n",
    "oof_rf = np.zeros(len(X))\n",
    "test_rf = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_scaled, y)):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=1000, max_depth=12, min_samples_leaf=10,\n",
    "        max_features=0.7, random_state=SEED, n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_scaled[tr_idx], y[tr_idx])\n",
    "    oof_rf[val_idx] = model.predict_proba(X_scaled[val_idx])[:, 1]\n",
    "    test_rf += model.predict_proba(X_test_scaled)[:, 1] / N_FOLDS\n",
    "\n",
    "rf_acc = accuracy_score(y, (oof_rf > 0.5).astype(int))\n",
    "print(f'RandomForest CV: {rf_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Correlation analysis ===\n",
    "print('=== Individual Model Scores ===')\n",
    "print(f'LightGBM:     {lgb_acc:.5f}')\n",
    "print(f'XGBoost:      {xgb_acc:.5f}')\n",
    "print(f'CatBoost:     {cb_acc:.5f}')\n",
    "print(f'ExtraTrees:   {et_acc:.5f}')\n",
    "print(f'RandomForest: {rf_acc:.5f}')\n",
    "\n",
    "models_oof = {'LGB': oof_lgb, 'XGB': oof_xgb, 'CB': oof_cb, 'ET': oof_et, 'RF': oof_rf}\n",
    "names = list(models_oof.keys())\n",
    "\n",
    "print('\\n=== OOF Correlations ===')\n",
    "for i in range(len(names)):\n",
    "    for j in range(i+1, len(names)):\n",
    "        corr = np.corrcoef(models_oof[names[i]], models_oof[names[j]])[0, 1]\n",
    "        marker = ' <-- diverse!' if corr < 0.95 else ''\n",
    "        print(f'  {names[i]}-{names[j]}: {corr:.4f}{marker}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble: Multiple Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Simple average (all 5 models)\n",
    "oof_avg5 = (oof_lgb + oof_xgb + oof_cb + oof_et + oof_rf) / 5\n",
    "avg5_acc = accuracy_score(y, (oof_avg5 > 0.5).astype(int))\n",
    "\n",
    "# Strategy 2: Simple average (3 GBDT only, like V5)\n",
    "oof_avg3 = (oof_lgb + oof_xgb + oof_cb) / 3\n",
    "avg3_acc = accuracy_score(y, (oof_avg3 > 0.5).astype(int))\n",
    "\n",
    "# Strategy 3: Weighted — give less weight to weaker models\n",
    "# GBDT: 0.25 each, ET/RF: 0.125 each (total = 1.0)\n",
    "oof_weighted = 0.25 * oof_lgb + 0.25 * oof_xgb + 0.25 * oof_cb + 0.125 * oof_et + 0.125 * oof_rf\n",
    "weighted_acc = accuracy_score(y, (oof_weighted > 0.5).astype(int))\n",
    "\n",
    "# Strategy 4: Majority voting (5 models)\n",
    "votes5 = ((oof_lgb > 0.5).astype(int) + (oof_xgb > 0.5).astype(int) + \n",
    "          (oof_cb > 0.5).astype(int) + (oof_et > 0.5).astype(int) + (oof_rf > 0.5).astype(int))\n",
    "vote5_acc = accuracy_score(y, (votes5 >= 3).astype(int))\n",
    "\n",
    "print('=== Ensemble Results ===')\n",
    "print(f'3-GBDT Average:    {avg3_acc:.5f}')\n",
    "print(f'5-Model Average:   {avg5_acc:.5f}')\n",
    "print(f'5-Model Weighted:  {weighted_acc:.5f}')\n",
    "print(f'5-Model Voting:    {vote5_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best ensemble strategy and generate submission\n",
    "results = {\n",
    "    '3-GBDT Avg': (avg3_acc, (test_lgb + test_xgb + test_cb) / 3),\n",
    "    '5-Model Avg': (avg5_acc, (test_lgb + test_xgb + test_cb + test_et + test_rf) / 5),\n",
    "    '5-Model Weighted': (weighted_acc, 0.25*test_lgb + 0.25*test_xgb + 0.25*test_cb + 0.125*test_et + 0.125*test_rf),\n",
    "}\n",
    "\n",
    "best_name = max(results, key=lambda k: results[k][0])\n",
    "best_acc = results[best_name][0]\n",
    "best_test_proba = results[best_name][1]\n",
    "\n",
    "print(f'Best ensemble: {best_name} (CV: {best_acc:.5f})')\n",
    "print(f'\\n=== VERSION COMPARISON ===')\n",
    "print(f'V2:  CV 0.81410 | LB 0.80710 | 29 feat | 3 GBDT avg')\n",
    "print(f'V5:  CV 0.81767 | LB 0.80874 | 32 feat | 3 GBDT avg')\n",
    "print(f'V8:  CV {best_acc:.5f} | LB TBD   | {len(features)} feat | {best_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (LightGBM)\n",
    "fi_df = pd.DataFrame({'feature': features, 'importance': fi_lgb})\n",
    "fi_df = fi_df.sort_values('importance', ascending=True).tail(25)\n",
    "\n",
    "colors = ['coral' if f not in v5_features else 'steelblue' for f in fi_df['feature']]\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(fi_df['feature'], fi_df['importance'], color=colors)\n",
    "plt.title(f'LightGBM V8 Feature Importance (coral = new features)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all promising submissions\n",
    "for name, (acc, test_proba) in results.items():\n",
    "    safe_name = name.replace(' ', '_').replace('-', '').lower()\n",
    "    preds = (test_proba > 0.5)\n",
    "    sub = pd.DataFrame({\n",
    "        'PassengerId': test_df['PassengerId'].values,\n",
    "        'Transported': preds.astype(bool)\n",
    "    })\n",
    "    fname = f'../submissions/submission_v8_{safe_name}.csv'\n",
    "    sub.to_csv(fname, index=False)\n",
    "    print(f'{name} (CV {acc:.5f}): {preds.sum()} True ({preds.mean():.4f}) -> {fname}')\n",
    "\n",
    "# Also save the best as main v8\n",
    "final_preds = (best_test_proba > 0.5)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'].values,\n",
    "    'Transported': final_preds.astype(bool)\n",
    "})\n",
    "submission.to_csv('../submissions/submission_v8.csv', index=False)\n",
    "\n",
    "assert submission.shape[0] == sample_sub.shape[0]\n",
    "assert list(submission.columns) == list(sample_sub.columns)\n",
    "\n",
    "print(f'\\nMain submission: submission_v8.csv ({best_name})')\n",
    "print(submission['Transported'].value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
