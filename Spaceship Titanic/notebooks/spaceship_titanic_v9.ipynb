{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - V9 (V5 + GroupSpend_max_log + 5-Model Ensemble)\n",
    "\n",
    "**History:**\n",
    "- V1: CV 0.8265 / LB 0.8020 (49 features, overfit)\n",
    "- V2: CV 0.8141 / LB 0.8071 (29 features, best LB baseline)\n",
    "- V3: CV 0.8184 / LB 0.8041 (56 features, TE on interactions = overfit)\n",
    "- V4: CV 0.8146 / LB 0.8055 (33 features, V2+simple EDA)\n",
    "- V5: CV 0.8177 / LB **0.8087** (32 features, BEST LB)\n",
    "- V6: CV 0.8165 / LB 0.8038 (Optuna = overfit on small data)\n",
    "- V7: CV 0.8159 / LB 0.8038 (Stacking, no help)\n",
    "- V8: CV 0.8211 / LB TBD (39 features, 5-model ensemble)\n",
    "\n",
    "**V9 Strategy:** Surgical feature addition from V8 analysis:\n",
    "- **Base**: V5 (32 features, best LB 0.80874)\n",
    "- **+1 feature**: `GroupSpend_max_log` — rank 7 in V8 importance (only V8 new feature in top 10)\n",
    "- **5-model ensemble**: LGB + XGB + CatBoost + ExtraTrees + RandomForest (V2 manual params)\n",
    "- Total: **33 features**, diverse ensemble for better generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "TARGET = 'Transported'\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything()\n",
    "print('V9 Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(f'Train: {train.shape}, Test: {test.shape}')\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test[TARGET] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "print(f'Combined: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering V9 = V2 Base (identical to V5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V2 Feature Engineering (IDENTICAL copy) ===\n",
    "\n",
    "# PassengerId\n",
    "df['_Group'] = df['PassengerId'].str.split('_').str[0].astype(int)\n",
    "df['GroupSize'] = df.groupby('_Group')['PassengerId'].transform('count')\n",
    "df['IsAlone'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "# Cabin\n",
    "df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "df['CabinNum'] = df['Cabin'].str.split('/').str[1].astype(float)\n",
    "df['Side'] = df['Cabin'].str.split('/').str[2]\n",
    "df['CabinRegion'] = (df['CabinNum'] // 100).astype(float)\n",
    "\n",
    "# Name\n",
    "df['Surname'] = df['Name'].str.split().str[-1]\n",
    "df['FamilySize'] = df.groupby('Surname')['PassengerId'].transform('count')\n",
    "df.loc[df['Surname'].isna(), 'FamilySize'] = 1\n",
    "\n",
    "# Booleans\n",
    "df['CryoSleep'] = df['CryoSleep'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df['VIP'] = df['VIP'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "\n",
    "print('Parsing done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V2 Imputation (identical) ===\n",
    "for col in spend_cols:\n",
    "    mask = (df['CryoSleep'] == 1) & (df[col].isna())\n",
    "    df.loc[mask, col] = 0\n",
    "\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) == 0)\n",
    "df.loc[mask, 'CryoSleep'] = 1\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) > 0)\n",
    "df.loc[mask, 'CryoSleep'] = 0\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(f'Imputation done. Nulls: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V2 Spending features (identical) ===\n",
    "df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "df['TotalSpend_log'] = np.log1p(df['TotalSpend'])\n",
    "df['NoSpend'] = (df['TotalSpend'] == 0).astype(int)\n",
    "df['NumServicesUsed'] = (df[spend_cols] > 0).sum(axis=1)\n",
    "\n",
    "for col in spend_cols:\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "\n",
    "df['LuxurySpend'] = np.log1p(df['Spa'] + df['VRDeck'] + df['RoomService'])\n",
    "df['BasicSpend'] = np.log1p(df['FoodCourt'] + df['ShoppingMall'])\n",
    "\n",
    "# Age\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 5, 12, 18, 30, 50, 80],\n",
    "                        labels=[0, 1, 2, 3, 4, 5]).astype(float)\n",
    "df['IsChild'] = (df['Age'] < 18).astype(float)\n",
    "\n",
    "# Interactions\n",
    "df['CryoSleep_NoSpend'] = ((df['CryoSleep'] == 1) & (df['TotalSpend'] == 0)).astype(int)\n",
    "\n",
    "# Group spending\n",
    "df['GroupSpend_mean'] = df.groupby('_Group')['TotalSpend'].transform('mean')\n",
    "df['GroupSpend_mean_log'] = np.log1p(df['GroupSpend_mean'])\n",
    "\n",
    "# Label encoding\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Frequency encoding\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_freq'] = df[col].map(freq)\n",
    "\n",
    "print('V2 features done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5 Target Encoding (Bayesian smoothed, 10-fold OOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === REGULARIZED TARGET ENCODING ===\n",
    "\n",
    "te_cols = ['HomePlanet', 'Destination', 'Deck']\n",
    "SMOOTHING = 20\n",
    "\n",
    "train_idx = df[df['is_train'] == 1].index\n",
    "test_idx = df[df['is_train'] == 0].index\n",
    "\n",
    "y_for_te = df.loc[train_idx, TARGET].map({True: 1.0, False: 0.0, 1: 1.0, 0: 0.0}).astype(float)\n",
    "df.loc[train_idx, '_target_float'] = y_for_te.values\n",
    "global_mean = float(y_for_te.mean())\n",
    "\n",
    "print(f'Global mean: {global_mean:.4f}')\n",
    "print(f'Smoothing factor: {SMOOTHING}')\n",
    "\n",
    "kf_te = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for col in te_cols:\n",
    "    col_te = f'{col}_te'\n",
    "    df[col_te] = global_mean\n",
    "    \n",
    "    for fold_train, fold_val in kf_te.split(train_idx, y_for_te):\n",
    "        fold_train_idx = train_idx[fold_train]\n",
    "        fold_val_idx = train_idx[fold_val]\n",
    "        stats = df.loc[fold_train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "        stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "        mapped = df.loc[fold_val_idx, col].map(stats['te']).fillna(global_mean)\n",
    "        df.loc[fold_val_idx, col_te] = mapped.values\n",
    "    \n",
    "    stats = df.loc[train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "    stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "    mapped = df.loc[test_idx, col].map(stats['te']).fillna(global_mean)\n",
    "    df.loc[test_idx, col_te] = mapped.values\n",
    "    \n",
    "    print(f'{col}_te values:')\n",
    "    print(df.loc[train_idx].groupby(col)[col_te].mean().sort_values())\n",
    "    print()\n",
    "\n",
    "df.drop('_target_float', axis=1, inplace=True)\n",
    "print('Target encoding done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V9 New Feature: GroupSpend_max_log\n",
    "\n",
    "**Rank 7** in V8 LightGBM importance (importance=350.7). The ONLY V8 new feature in the top 10.\n",
    "\n",
    "Captures: the maximum spending of any member in the travel group → strong signal for group behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V9 NEW FEATURE: GroupSpend_max_log ===\n",
    "df['GroupSpend_max'] = df.groupby('_Group')['TotalSpend'].transform('max')\n",
    "df['GroupSpend_max_log'] = np.log1p(df['GroupSpend_max'])\n",
    "\n",
    "print(f'GroupSpend_max_log stats:')\n",
    "print(df['GroupSpend_max_log'].describe())\n",
    "print(f'\\nCorrelation with GroupSpend_mean_log: {df[\"GroupSpend_max_log\"].corr(df[\"GroupSpend_mean_log\"]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEFINE FEATURES: V5 (32) + GroupSpend_max_log = 33 features ===\n",
    "drop_cols = [\n",
    "    'PassengerId', 'Name', 'Cabin', 'Surname', 'is_train', TARGET,\n",
    "    'HomePlanet', 'Destination', 'Deck', 'Side',\n",
    "    '_Group', 'CabinNum',\n",
    "    'TotalSpend', 'GroupSpend_mean',\n",
    "    'GroupSpend_max',  # keep only the log version\n",
    "] + spend_cols\n",
    "\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f'V9 features: {len(features)} (V5: 32 + 1 new = 33)')\n",
    "print()\n",
    "for i, f in enumerate(sorted(features)):\n",
    "    marker = ' *** NEW V9' if f == 'GroupSpend_max_log' else (' [TE]' if f.endswith('_te') else '')\n",
    "    print(f'  {i+1:2d}. {f}{marker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[TARGET].astype(int).values\n",
    "X_test = test_df[features].values\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}')\n",
    "print(f'Target mean: {np.mean(y):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: LightGBM (V2 manual params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 20,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 30,\n",
    "    'reg_alpha': 0.5,\n",
    "    'reg_lambda': 2.0,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 5000,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': SEED,\n",
    "}\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "fi_lgb = np.zeros(len(features))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    oof_lgb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_lgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    fi_lgb += model.feature_importances_ / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_lgb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "lgb_acc = accuracy_score(y, (oof_lgb > 0.5).astype(int))\n",
    "print(f'\\nLightGBM V9 CV: {lgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost (V2 manual params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 10,\n",
    "    'reg_alpha': 0.5,\n",
    "    'reg_lambda': 2.0,\n",
    "    'gamma': 0.1,\n",
    "    'n_estimators': 5000,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': SEED,\n",
    "    'verbosity': 0,\n",
    "}\n",
    "\n",
    "oof_xgb = np.zeros(len(X))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=500)\n",
    "    \n",
    "    oof_xgb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_xgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_xgb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "xgb_acc = accuracy_score(y, (oof_xgb > 0.5).astype(int))\n",
    "print(f'\\nXGBoost V9 CV: {xgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: CatBoost (V2 manual params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_cb = np.zeros(len(X))\n",
    "test_cb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations=5000,\n",
    "        learning_rate=0.03,\n",
    "        depth=4,\n",
    "        l2_leaf_reg=5.0,\n",
    "        subsample=0.7,\n",
    "        colsample_bylevel=0.7,\n",
    "        min_data_in_leaf=30,\n",
    "        random_seed=SEED,\n",
    "        verbose=500,\n",
    "        early_stopping_rounds=200,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    \n",
    "    model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "    \n",
    "    oof_cb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_cb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_cb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "cb_acc = accuracy_score(y, (oof_cb > 0.5).astype(int))\n",
    "print(f'\\nCatBoost V9 CV: {cb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: ExtraTrees (diversity booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_et = np.zeros(len(X))\n",
    "test_et = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = ExtraTreesClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=10,\n",
    "        max_features=0.7,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    oof_et[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_et += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_et[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "et_acc = accuracy_score(y, (oof_et > 0.5).astype(int))\n",
    "print(f'\\nExtraTrees V9 CV: {et_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: RandomForest (diversity booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_rf = np.zeros(len(X))\n",
    "test_rf = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[tr_idx], X[val_idx]\n",
    "    y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=2000,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=10,\n",
    "        max_features=0.7,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    oof_rf[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_rf += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_rf[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "rf_acc = accuracy_score(y, (oof_rf > 0.5).astype(int))\n",
    "print(f'\\nRandomForest V9 CV: {rf_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df = pd.DataFrame({'feature': features, 'importance': fi_lgb})\n",
    "fi_df = fi_df.sort_values('importance', ascending=True).tail(20)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "colors = ['coral' if f == 'GroupSpend_max_log' else ('gold' if f.endswith('_te') else 'steelblue') \n",
    "          for f in fi_df['feature']]\n",
    "plt.barh(fi_df['feature'], fi_df['importance'], color=colors)\n",
    "plt.title(f'LightGBM V9 Feature Importance - CV: {lgb_acc:.5f}\\n(coral=V9 new, gold=TE, blue=V2 base)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Analysis & Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== V9 Individual Model Results ===')\n",
    "print(f'LightGBM:    {lgb_acc:.5f}')\n",
    "print(f'XGBoost:     {xgb_acc:.5f}')\n",
    "print(f'CatBoost:    {cb_acc:.5f}')\n",
    "print(f'ExtraTrees:  {et_acc:.5f}')\n",
    "print(f'RandomForest:{rf_acc:.5f}')\n",
    "\n",
    "# OOF correlations\n",
    "print('\\n=== OOF Correlations ===')\n",
    "oof_all = pd.DataFrame({\n",
    "    'LGB': oof_lgb, 'XGB': oof_xgb, 'CB': oof_cb, 'ET': oof_et, 'RF': oof_rf\n",
    "})\n",
    "print(oof_all.corr().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ENSEMBLE STRATEGIES ===\n",
    "\n",
    "# 1. 3-Model GBDT Average (like V5)\n",
    "oof_3avg = (oof_lgb + oof_xgb + oof_cb) / 3\n",
    "acc_3avg = accuracy_score(y, (oof_3avg > 0.5).astype(int))\n",
    "test_3avg = (test_lgb + test_xgb + test_cb) / 3\n",
    "\n",
    "# 2. 5-Model Equal Average\n",
    "oof_5avg = (oof_lgb + oof_xgb + oof_cb + oof_et + oof_rf) / 5\n",
    "acc_5avg = accuracy_score(y, (oof_5avg > 0.5).astype(int))\n",
    "test_5avg = (test_lgb + test_xgb + test_cb + test_et + test_rf) / 5\n",
    "\n",
    "# 3. 5-Model Weighted (GBDT heavier, ET/RF lighter for diversity)\n",
    "w_lgb, w_xgb, w_cb, w_et, w_rf = 0.25, 0.25, 0.25, 0.125, 0.125\n",
    "oof_5w = w_lgb*oof_lgb + w_xgb*oof_xgb + w_cb*oof_cb + w_et*oof_et + w_rf*oof_rf\n",
    "acc_5w = accuracy_score(y, (oof_5w > 0.5).astype(int))\n",
    "test_5w = w_lgb*test_lgb + w_xgb*test_xgb + w_cb*test_cb + w_et*test_et + w_rf*test_rf\n",
    "\n",
    "# 4. Majority voting (5 models)\n",
    "votes = ((oof_lgb > 0.5).astype(int) + (oof_xgb > 0.5).astype(int) + \n",
    "         (oof_cb > 0.5).astype(int) + (oof_et > 0.5).astype(int) + \n",
    "         (oof_rf > 0.5).astype(int))\n",
    "acc_vote = accuracy_score(y, (votes >= 3).astype(int))\n",
    "\n",
    "# 5. Optimized grid search on weights\n",
    "best_acc = 0\n",
    "best_weights = None\n",
    "for w_gbdt in np.arange(0.20, 0.36, 0.01):\n",
    "    for w_tree in np.arange(0.05, 0.21, 0.01):\n",
    "        w_rem = 1.0 - 3*w_gbdt - 2*w_tree\n",
    "        if abs(w_rem) > 0.01:  # must sum to ~1\n",
    "            continue\n",
    "        oof_try = w_gbdt*oof_lgb + w_gbdt*oof_xgb + w_gbdt*oof_cb + w_tree*oof_et + w_tree*oof_rf\n",
    "        acc_try = accuracy_score(y, (oof_try > 0.5).astype(int))\n",
    "        if acc_try > best_acc:\n",
    "            best_acc = acc_try\n",
    "            best_weights = (w_gbdt, w_tree)\n",
    "\n",
    "if best_weights:\n",
    "    w_g, w_t = best_weights\n",
    "    oof_opt = w_g*oof_lgb + w_g*oof_xgb + w_g*oof_cb + w_t*oof_et + w_t*oof_rf\n",
    "    acc_opt = accuracy_score(y, (oof_opt > 0.5).astype(int))\n",
    "    test_opt = w_g*test_lgb + w_g*test_xgb + w_g*test_cb + w_t*test_et + w_t*test_rf\n",
    "else:\n",
    "    acc_opt = acc_5w\n",
    "    test_opt = test_5w\n",
    "    w_g, w_t = 0.25, 0.125\n",
    "\n",
    "print('=== ENSEMBLE RESULTS ===')\n",
    "print(f'3-Model GBDT Avg:       {acc_3avg:.5f}')\n",
    "print(f'5-Model Equal Avg:      {acc_5avg:.5f}')\n",
    "print(f'5-Model Weighted:       {acc_5w:.5f}  (GBDT 0.25 each, ET/RF 0.125 each)')\n",
    "print(f'5-Model Majority Vote:  {acc_vote:.5f}')\n",
    "print(f'5-Model Optimized:      {acc_opt:.5f}  (GBDT {w_g:.2f} each, ET/RF {w_t:.2f} each)')\n",
    "\n",
    "print(f'\\n=== VERSION COMPARISON ===')\n",
    "print(f'V1: CV 0.82653 | LB 0.80196 | 49 features')\n",
    "print(f'V2: CV 0.81410 | LB 0.80710 | 29 features')\n",
    "print(f'V3: CV 0.81836 | LB 0.80406 | 56 features')\n",
    "print(f'V4: CV 0.81456 | LB 0.80547 | 33 features')\n",
    "print(f'V5: CV 0.81767 | LB 0.80874 | 32 features (BEST LB)')\n",
    "print(f'V8: CV 0.82112 | LB TBD     | 39 features')\n",
    "print(f'V9: CV {acc_opt:.5f} | LB TBD     | {len(features)} features (V5 + 1 feature + 5 models)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUBMISSIONS ===\n",
    "\n",
    "# Primary: best ensemble (optimized weights)\n",
    "final_preds = (test_opt > 0.5)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'].values,\n",
    "    'Transported': final_preds\n",
    "})\n",
    "submission['Transported'] = submission['Transported'].astype(bool)\n",
    "submission.to_csv('../submissions/submission_v9.csv', index=False)\n",
    "\n",
    "assert submission.shape[0] == sample_sub.shape[0]\n",
    "assert list(submission.columns) == list(sample_sub.columns)\n",
    "\n",
    "print(f'V9 Primary (Optimized 5-model): saved to submissions/submission_v9.csv')\n",
    "print(f'  True: {final_preds.sum()}, False: {(~final_preds).sum()}, Ratio: {final_preds.mean():.4f}')\n",
    "\n",
    "# Safe fallback: 3-model GBDT average (closest to V5 which had best LB)\n",
    "final_safe = (test_3avg > 0.5)\n",
    "submission_safe = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'].values,\n",
    "    'Transported': final_safe\n",
    "})\n",
    "submission_safe['Transported'] = submission_safe['Transported'].astype(bool)\n",
    "submission_safe.to_csv('../submissions/submission_v9_3model.csv', index=False)\n",
    "\n",
    "print(f'\\nV9 Safe (3-GBDT avg): saved to submissions/submission_v9_3model.csv')\n",
    "print(f'  True: {final_safe.sum()}, False: {(~final_safe).sum()}, Ratio: {final_safe.mean():.4f}')\n",
    "\n",
    "# How many predictions differ between the two?\n",
    "diff = (final_preds != final_safe).sum()\n",
    "print(f'\\nDifferences between 5-model and 3-model: {diff} ({diff/len(final_preds)*100:.1f}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
