{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - V3 (EDA-Driven Features)\n",
    "\n",
    "**V1:** CV 0.8265 / LB 0.8020 (overfitting)  \n",
    "**V2:** CV 0.8141 / LB 0.8071 (clean, good ratio)  \n",
    "**V3 Goal:** Add EDA-driven features that generalize well  \n",
    "\n",
    "**New features from EDA:**\n",
    "- Deck x Side interaction\n",
    "- HomePlanet x Deck interaction  \n",
    "- Fine age buckets (baby/child/teen/adult)\n",
    "- Spending profile (% per category)\n",
    "- Non-CryoSleep + NoSpend signal\n",
    "- n_missing as feature\n",
    "- Target encoding (CV-safe) for key categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "TARGET = 'Transported'\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything()\n",
    "print('V3 Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train = pd.read_csv('../data/train.csv')\ntest = pd.read_csv('../data/test.csv')\nsample_sub = pd.read_csv('../data/sample_submission.csv')\n\ntrain['is_train'] = 1\ntest['is_train'] = 0\ntest[TARGET] = np.nan\ndf = pd.concat([train, test], axis=0, ignore_index=True)\n\n# Convert target to float early (True->1.0, False->0.0, NaN stays NaN)\ndf[TARGET] = df[TARGET].map({True: 1.0, False: 0.0})\n\nspend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\nprint(f'Combined: {df.shape}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: Parse raw columns\n",
    "# ============================================================\n",
    "\n",
    "# PassengerId -> Group, GroupSize\n",
    "df['_Group'] = df['PassengerId'].str.split('_').str[0].astype(int)\n",
    "df['GroupSize'] = df.groupby('_Group')['PassengerId'].transform('count')\n",
    "df['IsAlone'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "# Cabin -> Deck, CabinNum, Side\n",
    "df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "df['CabinNum'] = df['Cabin'].str.split('/').str[1].astype(float)\n",
    "df['Side'] = df['Cabin'].str.split('/').str[2]\n",
    "\n",
    "# Name -> Surname, FamilySize\n",
    "df['Surname'] = df['Name'].str.split().str[-1]\n",
    "df['FamilySize'] = df.groupby('Surname')['PassengerId'].transform('count')\n",
    "df.loc[df['Surname'].isna(), 'FamilySize'] = 1\n",
    "\n",
    "# Booleans\n",
    "df['CryoSleep'] = df['CryoSleep'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df['VIP'] = df['VIP'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "\n",
    "print('Step 1 done: raw parsing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: Smart imputation BEFORE feature engineering\n",
    "# ============================================================\n",
    "\n",
    "# CryoSleep passengers must have 0 spending\n",
    "for col in spend_cols:\n",
    "    mask = (df['CryoSleep'] == 1) & (df[col].isna())\n",
    "    df.loc[mask, col] = 0\n",
    "\n",
    "# Infer CryoSleep from spending\n",
    "total_spend_raw = df[spend_cols].sum(axis=1)\n",
    "df.loc[(df['CryoSleep'].isna()) & (total_spend_raw == 0), 'CryoSleep'] = 1\n",
    "df.loc[(df['CryoSleep'].isna()) & (total_spend_raw > 0), 'CryoSleep'] = 0\n",
    "\n",
    "# HomePlanet can be inferred from Deck (EDA insight)\n",
    "# Europa -> B,C,A,T ; Earth -> F,G,E(partial) ; Mars -> F,D,E(partial)\n",
    "deck_to_planet = {\n",
    "    'A': 'Europa', 'B': 'Europa', 'C': 'Europa', 'T': 'Europa',\n",
    "    'G': 'Earth'\n",
    "}\n",
    "for deck, planet in deck_to_planet.items():\n",
    "    mask = (df['HomePlanet'].isna()) & (df['Deck'] == deck)\n",
    "    df.loc[mask, 'HomePlanet'] = planet\n",
    "\n",
    "# Fill remaining with median/mode\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(f'Step 2 done: imputation. Nulls remaining: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: Spending features (EDA-driven)\n",
    "# ============================================================\n",
    "\n",
    "# Total and log transforms\n",
    "df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "df['TotalSpend_log'] = np.log1p(df['TotalSpend'])\n",
    "df['NoSpend'] = (df['TotalSpend'] == 0).astype(int)\n",
    "df['NumServicesUsed'] = (df[spend_cols] > 0).sum(axis=1)\n",
    "\n",
    "for col in spend_cols:\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "\n",
    "# NEW: Spending PROFILE (% per category) - EDA showed this discriminates\n",
    "for col in spend_cols:\n",
    "    df[f'{col}_pct'] = df[col] / (df['TotalSpend'] + 1)\n",
    "\n",
    "# NEW: Luxury vs Basic (EDA: not-transported = luxury spenders)\n",
    "df['LuxurySpend'] = df['RoomService'] + df['Spa'] + df['VRDeck']\n",
    "df['BasicSpend'] = df['FoodCourt'] + df['ShoppingMall']\n",
    "df['LuxurySpend_log'] = np.log1p(df['LuxurySpend'])\n",
    "df['BasicSpend_log'] = np.log1p(df['BasicSpend'])\n",
    "df['LuxuryRatio'] = df['LuxurySpend'] / (df['TotalSpend'] + 1)\n",
    "\n",
    "# NEW: Binary spending flags\n",
    "df['HasLuxurySpend'] = (df['LuxurySpend'] > 0).astype(int)\n",
    "df['HasBasicSpend'] = (df['BasicSpend'] > 0).astype(int)\n",
    "\n",
    "# NEW: Non-CryoSleep with no spending (EDA: 62% transported)\n",
    "df['Awake_NoSpend'] = ((df['CryoSleep'] == 0) & (df['TotalSpend'] == 0)).astype(int)\n",
    "\n",
    "print('Step 3 done: spending features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: Age features (EDA-driven fine buckets)\n",
    "# ============================================================\n",
    "\n",
    "# Fine age buckets based on EDA\n",
    "df['IsBaby'] = (df['Age'] <= 4).astype(float)      # 81% transported\n",
    "df['IsChild'] = ((df['Age'] > 4) & (df['Age'] < 13)).astype(float)  # ~65% transported\n",
    "df['IsTeen'] = ((df['Age'] >= 13) & (df['Age'] < 18)).astype(float)  # ~55%\n",
    "df['IsYoungAdult'] = ((df['Age'] >= 18) & (df['Age'] < 30)).astype(float)\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 4, 12, 17, 30, 50, 80],\n",
    "                        labels=[0, 1, 2, 3, 4, 5]).astype(float)\n",
    "\n",
    "# NEW: Children under 13 cannot spend on certain things\n",
    "df['IsMinor'] = (df['Age'] < 13).astype(float)  # baby + child\n",
    "\n",
    "print('Step 4 done: age features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 5: Cabin features (EDA-driven interactions)\n",
    "# ============================================================\n",
    "\n",
    "# Broad cabin region (not too granular)\n",
    "df['CabinRegion'] = (df['CabinNum'] // 100).astype(float)\n",
    "\n",
    "# NEW: Deck x Side interaction (EDA showed some combos very predictive)\n",
    "df['DeckSide'] = df['Deck'] + '_' + df['Side']\n",
    "\n",
    "# NEW: HomePlanet x Deck interaction (EDA: HP determines Deck)\n",
    "df['PlanetDeck'] = df['HomePlanet'] + '_' + df['Deck']\n",
    "\n",
    "# NEW: HomePlanet x Destination\n",
    "df['PlanetDest'] = df['HomePlanet'] + '_' + df['Destination']\n",
    "\n",
    "print('Step 5 done: cabin interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 6: n_missing and data quality features\n",
    "# ============================================================\n",
    "\n",
    "# We need original data for this, reload briefly\n",
    "train_orig = pd.read_csv('../data/train.csv')\n",
    "test_orig = pd.read_csv('../data/test.csv')\n",
    "test_orig[TARGET] = np.nan\n",
    "df_orig = pd.concat([train_orig, test_orig], axis=0, ignore_index=True)\n",
    "\n",
    "df['n_missing'] = df_orig.isnull().sum(axis=1)\n",
    "df['has_missing'] = (df['n_missing'] > 0).astype(int)\n",
    "\n",
    "del train_orig, test_orig, df_orig\n",
    "print('Step 6 done: missing features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 7: Group-level features (safe, no survival leakage)\n",
    "# ============================================================\n",
    "\n",
    "# Group spending (computed on combined train+test = no leakage)\n",
    "df['GroupSpend_mean_log'] = np.log1p(df.groupby('_Group')['TotalSpend'].transform('mean'))\n",
    "df['GroupSpend_std'] = df.groupby('_Group')['TotalSpend'].transform('std').fillna(0)\n",
    "\n",
    "# Group age stats\n",
    "df['GroupAge_mean'] = df.groupby('_Group')['Age'].transform('mean')\n",
    "df['GroupAge_std'] = df.groupby('_Group')['Age'].transform('std').fillna(0)\n",
    "\n",
    "# Group CryoSleep rate (from combined data = safe)\n",
    "df['GroupCryo_rate'] = df.groupby('_Group')['CryoSleep'].transform('mean')\n",
    "\n",
    "print('Step 7 done: group features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 8: Encode all categoricals\n",
    "# ============================================================\n",
    "\n",
    "# Label encode low-cardinality categoricals\n",
    "label_cols = ['HomePlanet', 'Destination', 'Deck', 'Side']\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Frequency encode (low cardinality = safe)\n",
    "for col in label_cols:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_freq'] = df[col].map(freq)\n",
    "\n",
    "# NEW: Frequency encode interaction features\n",
    "for col in ['DeckSide', 'PlanetDeck', 'PlanetDest']:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_freq'] = df[col].map(freq)\n",
    "\n",
    "print('Step 8 done: encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 9: Target encoding (CV-safe) for key categoricals\n# ============================================================\n\ntrain_mask = df['is_train'] == 1\ntrain_idx = df[train_mask].index\ntest_idx = df[~train_mask].index\n\nte_cols = ['DeckSide', 'PlanetDeck', 'PlanetDest', 'Deck']\nkf_te = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\ny_train_te = df.loc[train_idx, TARGET].astype(int).values\n\nfor col in te_cols:\n    df[col + '_te'] = 0.5  # initialize with prior\n    global_mean = float(y_train_te.mean())\n    \n    # OOF target encoding for train\n    for fold_train, fold_val in kf_te.split(train_idx, y_train_te):\n        fold_train_idx = train_idx[fold_train]\n        fold_val_idx = train_idx[fold_val]\n        \n        means = df.loc[fold_train_idx].groupby(col)[TARGET].mean()\n        mapped = df.loc[fold_val_idx, col].map(means).fillna(global_mean)\n        df.loc[fold_val_idx, col + '_te'] = mapped.values\n    \n    # For test: use full train\n    means = df.loc[train_idx].groupby(col)[TARGET].mean()\n    mapped = df.loc[test_idx, col].map(means).fillna(global_mean)\n    df.loc[test_idx, col + '_te'] = mapped.values\n\nprint('Step 9 done: target encoding')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEFINE FINAL FEATURES\n",
    "# ============================================================\n",
    "\n",
    "drop_cols = [\n",
    "    'PassengerId', 'Name', 'Cabin', 'Surname', 'is_train', TARGET,\n",
    "    'HomePlanet', 'Destination', 'Deck', 'Side',\n",
    "    '_Group', 'CabinNum',\n",
    "    'TotalSpend', 'LuxurySpend', 'BasicSpend', 'GroupSpend_std',\n",
    "    'DeckSide', 'PlanetDeck', 'PlanetDest',\n",
    "] + spend_cols\n",
    "\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f'V3 features: {len(features)}')\n",
    "print()\n",
    "for i, f in enumerate(sorted(features)):\n",
    "    print(f'  {i+1:2d}. {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[TARGET].values.astype(int)\n",
    "X_test = test_df[features].values\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}')\n",
    "print(f'Target: {np.mean(y):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 24,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 25,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 1.5,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 5000,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': SEED,\n",
    "}\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "fi_lgb = np.zeros(len(features))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    oof_lgb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_lgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    fi_lgb += model.feature_importances_ / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_lgb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "lgb_acc = accuracy_score(y, (oof_lgb > 0.5).astype(int))\n",
    "print(f'\\nLightGBM V3 CV: {lgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "fi_df = pd.DataFrame({'feature': features, 'importance': fi_lgb})\n",
    "fi_df = fi_df.sort_values('importance', ascending=True).tail(25)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(fi_df['feature'], fi_df['importance'], color='steelblue')\n",
    "plt.title(f'LightGBM V3 Feature Importance (Top 25) - CV: {lgb_acc:.5f}')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 8,\n",
    "    'reg_alpha': 0.3,\n",
    "    'reg_lambda': 1.5,\n",
    "    'gamma': 0.05,\n",
    "    'n_estimators': 5000,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': SEED,\n",
    "    'verbosity': 0,\n",
    "}\n",
    "\n",
    "oof_xgb = np.zeros(len(X))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=500)\n",
    "    \n",
    "    oof_xgb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_xgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_xgb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "xgb_acc = accuracy_score(y, (oof_xgb > 0.5).astype(int))\n",
    "print(f'\\nXGBoost V3 CV: {xgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_cb = np.zeros(len(X))\n",
    "test_cb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations=5000,\n",
    "        learning_rate=0.03,\n",
    "        depth=5,\n",
    "        l2_leaf_reg=4.0,\n",
    "        subsample=0.7,\n",
    "        colsample_bylevel=0.7,\n",
    "        min_data_in_leaf=25,\n",
    "        random_seed=SEED,\n",
    "        verbose=500,\n",
    "        early_stopping_rounds=200,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    \n",
    "    model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "    \n",
    "    oof_cb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_cb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_cb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "cb_acc = accuracy_score(y, (oof_cb > 0.5).astype(int))\n",
    "print(f'\\nCatBoost V3 CV: {cb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== V3 Results ===')\n",
    "print(f'LightGBM: {lgb_acc:.5f}')\n",
    "print(f'XGBoost:  {xgb_acc:.5f}')\n",
    "print(f'CatBoost: {cb_acc:.5f}')\n",
    "\n",
    "# Simple average (safest)\n",
    "oof_avg = (oof_lgb + oof_xgb + oof_cb) / 3\n",
    "avg_acc = accuracy_score(y, (oof_avg > 0.5).astype(int))\n",
    "print(f'\\nSimple Average: {avg_acc:.5f}')\n",
    "\n",
    "# Majority voting\n",
    "votes = ((oof_lgb > 0.5).astype(int) + (oof_xgb > 0.5).astype(int) + (oof_cb > 0.5).astype(int))\n",
    "vote_acc = accuracy_score(y, (votes >= 2).astype(int))\n",
    "print(f'Majority Voting: {vote_acc:.5f}')\n",
    "\n",
    "# Use simple average for submission\n",
    "final_proba = (test_lgb + test_xgb + test_cb) / 3\n",
    "final_preds = (final_proba > 0.5)\n",
    "\n",
    "print(f'\\nTest: {final_preds.sum()} True / {len(final_preds) - final_preds.sum()} False')\n",
    "print(f'Ratio: {final_preds.mean():.4f}')\n",
    "\n",
    "print(f'\\n=== VERSION COMPARISON ===')\n",
    "print(f'V1: CV 0.82653 | LB 0.80196 | Gap 0.0246')\n",
    "print(f'V2: CV 0.81410 | LB 0.80710 | Gap 0.0070')\n",
    "print(f'V3: CV {avg_acc:.5f} | LB TBD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'].values,\n",
    "    'Transported': final_preds\n",
    "})\n",
    "submission['Transported'] = submission['Transported'].astype(bool)\n",
    "submission.to_csv('../submissions/submission_v3.csv', index=False)\n",
    "\n",
    "assert submission.shape[0] == sample_sub.shape[0]\n",
    "assert list(submission.columns) == list(sample_sub.columns)\n",
    "assert submission['Transported'].dtype == bool\n",
    "\n",
    "print('V3 Submission saved: submissions/submission_v3.csv')\n",
    "print(submission['Transported'].value_counts(normalize=True))\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}