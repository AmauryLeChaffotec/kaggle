{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - Complete Pipeline\n",
    "\n",
    "**Competition:** Spaceship Titanic (Kaggle)  \n",
    "**Problem:** Binary Classification (Transported: True/False)  \n",
    "**Metric:** Accuracy  \n",
    "**Data:** ~8700 train / ~4300 test / 14 features  \n",
    "**Strategy:** Feature Engineering + LightGBM + XGBoost + CatBoost Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import optuna\n",
    "from scipy.stats import rankdata\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "TARGET = 'Transported'\n",
    "\n",
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape:  {test.shape}')\n",
    "print(f'Submission:  {sample_sub.shape}')\n",
    "print(f'\\nTarget distribution:')\n",
    "print(train[TARGET].value_counts(normalize=True))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== DATA INFO ===')\n",
    "print(f'\\nColumns ({len(train.columns)}):')\n",
    "for col in train.columns:\n",
    "    dtype = train[col].dtype\n",
    "    nunique = train[col].nunique()\n",
    "    null_pct = train[col].isnull().mean() * 100\n",
    "    print(f'  {col:20s} | {str(dtype):10s} | {nunique:6d} unique | {null_pct:5.2f}% missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values comparison train vs test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "train_miss = train.isnull().mean().sort_values(ascending=False) * 100\n",
    "test_miss = test.isnull().mean().sort_values(ascending=False) * 100\n",
    "\n",
    "train_miss[train_miss > 0].plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Train - Missing %')\n",
    "axes[0].set_xlabel('%')\n",
    "\n",
    "test_miss[test_miss > 0].plot(kind='barh', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Test - Missing %')\n",
    "axes[1].set_xlabel('%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target vs categorical features\n",
    "cat_cols_eda = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "for ax, col in zip(axes.flatten(), cat_cols_eda):\n",
    "    ct = pd.crosstab(train[col], train[TARGET], normalize='index') * 100\n",
    "    ct.plot(kind='bar', stacked=True, ax=ax, colormap='RdYlGn')\n",
    "    ax.set_title(f'{col} vs Transported')\n",
    "    ax.set_ylabel('% Transported')\n",
    "    ax.legend(title='Transported')\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spending columns distribution by Transported\n",
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for ax, col in zip(axes, spend_cols):\n",
    "    for transported in [True, False]:\n",
    "        subset = train[train[TARGET] == transported][col].dropna()\n",
    "        # Log transform for better visualization\n",
    "        subset_log = np.log1p(subset)\n",
    "        ax.hist(subset_log, bins=30, alpha=0.5, label=str(transported), density=True)\n",
    "    ax.set_title(col)\n",
    "    ax.legend(title='Transported', fontsize=8)\n",
    "    ax.set_xlabel('log1p(amount)')\n",
    "\n",
    "plt.suptitle('Spending Distributions by Transported (log scale)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution by Transported\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for transported in [True, False]:\n",
    "    subset = train[train[TARGET] == transported]['Age'].dropna()\n",
    "    axes[0].hist(subset, bins=40, alpha=0.5, label=str(transported), density=True)\n",
    "axes[0].set_title('Age Distribution by Transported')\n",
    "axes[0].legend(title='Transported')\n",
    "axes[0].set_xlabel('Age')\n",
    "\n",
    "# Cabin Deck extraction for quick look\n",
    "train_temp = train.copy()\n",
    "train_temp['Deck'] = train_temp['Cabin'].str.split('/').str[0]\n",
    "ct = pd.crosstab(train_temp['Deck'], train_temp[TARGET], normalize='index') * 100\n",
    "ct[True].sort_values().plot(kind='barh', ax=axes[1], color='seagreen')\n",
    "axes[1].set_title('% Transported by Deck')\n",
    "axes[1].set_xlabel('% Transported')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "del train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key EDA insights\n",
    "print('=== KEY EDA INSIGHTS ===')\n",
    "print()\n",
    "print('1. CryoSleep is the STRONGEST predictor (~80% transported if True)')\n",
    "print('2. Europa passengers more likely transported than Earth/Mars')\n",
    "print('3. CryoSleep passengers have 0 spending (logical: they are asleep)')\n",
    "print('4. Younger passengers (<18) slightly more likely transported')\n",
    "print('5. Cabin Deck B & C have highest transport rates')\n",
    "print('6. VIP passengers LESS likely transported')\n",
    "print('7. Higher spending generally correlates with NOT transported')\n",
    "print('8. PassengerId encodes group structure (XXXX_YY = group_member)')\n",
    "print('9. ~2% missing values across most columns - manageable')\n",
    "print('10. Target is well balanced (~50/50)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train+test for consistent feature engineering\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test[TARGET] = np.nan\n",
    "\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "print(f'Combined shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Complete feature engineering pipeline.\"\"\"\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.1 - PassengerId decomposition\n",
    "    # =========================================================\n",
    "    df['Group'] = df['PassengerId'].str.split('_').str[0].astype(int)\n",
    "    df['MemberNum'] = df['PassengerId'].str.split('_').str[1].astype(int)\n",
    "    df['GroupSize'] = df.groupby('Group')['PassengerId'].transform('count')\n",
    "    df['IsAlone'] = (df['GroupSize'] == 1).astype(int)\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.2 - Cabin decomposition\n",
    "    # =========================================================\n",
    "    df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "    df['CabinNum'] = df['Cabin'].str.split('/').str[1].astype(float)\n",
    "    df['Side'] = df['Cabin'].str.split('/').str[2]\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.3 - Name features\n",
    "    # =========================================================\n",
    "    df['Surname'] = df['Name'].str.split().str[-1]\n",
    "    df['FamilySize'] = df.groupby('Surname')['PassengerId'].transform('count')\n",
    "    # Handle NaN surnames\n",
    "    df.loc[df['Surname'].isna(), 'FamilySize'] = 1\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.4 - Spending features\n",
    "    # =========================================================\n",
    "    df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "    df['NoSpend'] = (df['TotalSpend'] == 0).astype(int)\n",
    "    df['NumServicesUsed'] = (df[spend_cols] > 0).sum(axis=1)\n",
    "    \n",
    "    # Luxury vs basic spending\n",
    "    df['LuxurySpend'] = df['Spa'] + df['VRDeck'] + df['RoomService']\n",
    "    df['BasicSpend'] = df['FoodCourt'] + df['ShoppingMall']\n",
    "    \n",
    "    # Spending ratios (avoid division by zero)\n",
    "    df['LuxuryRatio'] = df['LuxurySpend'] / (df['TotalSpend'] + 1)\n",
    "    df['BasicRatio'] = df['BasicSpend'] / (df['TotalSpend'] + 1)\n",
    "    \n",
    "    # Max single spending category\n",
    "    df['MaxSpend'] = df[spend_cols].max(axis=1)\n",
    "    df['MaxSpendCategory'] = df[spend_cols].idxmax(axis=1)\n",
    "    \n",
    "    # Log transforms of spending\n",
    "    for col in spend_cols:\n",
    "        df[f'{col}_log'] = np.log1p(df[col])\n",
    "    df['TotalSpend_log'] = np.log1p(df['TotalSpend'])\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.5 - Boolean features\n",
    "    # =========================================================\n",
    "    df['CryoSleep'] = df['CryoSleep'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    df['VIP'] = df['VIP'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.6 - Age features\n",
    "    # =========================================================\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 5, 12, 18, 30, 50, 80], \n",
    "                            labels=[0, 1, 2, 3, 4, 5]).astype(float)\n",
    "    df['IsChild'] = (df['Age'] < 18).astype(float)\n",
    "    df['IsElder'] = (df['Age'] >= 50).astype(float)\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.7 - Interaction features\n",
    "    # =========================================================\n",
    "    df['CryoSleep_NoSpend'] = ((df['CryoSleep'] == 1) & (df['TotalSpend'] == 0)).astype(int)\n",
    "    df['Age_TotalSpend'] = df['Age'] * df['TotalSpend_log']\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.8 - Group-level features (inspired by titanicv2)\n",
    "    # =========================================================\n",
    "    # Average spending per group\n",
    "    df['GroupSpend_mean'] = df.groupby('Group')['TotalSpend'].transform('mean')\n",
    "    df['GroupSpend_max'] = df.groupby('Group')['TotalSpend'].transform('max')\n",
    "    df['GroupAge_mean'] = df.groupby('Group')['Age'].transform('mean')\n",
    "    \n",
    "    # Cabin density\n",
    "    df['CabinNum_rounded'] = (df['CabinNum'] // 10).astype(float)\n",
    "    \n",
    "    # =========================================================\n",
    "    # 4.9 - Encode categoricals\n",
    "    # =========================================================\n",
    "    label_cols = ['HomePlanet', 'Destination', 'Deck', 'Side', 'MaxSpendCategory']\n",
    "    label_encoders = {}\n",
    "    for col in label_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Frequency encodings\n",
    "    for col in ['HomePlanet', 'Destination', 'Deck', 'Side', 'Surname']:\n",
    "        freq = df[col].value_counts(normalize=True)\n",
    "        df[col + '_freq'] = df[col].map(freq)\n",
    "    \n",
    "    return df, label_encoders\n",
    "\n",
    "df, label_encoders = feature_engineering(df)\n",
    "print(f'Features after engineering: {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 4.10 - Smart imputation (after feature engineering)\n",
    "# =========================================================\n",
    "\n",
    "# CryoSleep passengers must have 0 spending\n",
    "for col in spend_cols:\n",
    "    mask = (df['CryoSleep'] == 1) & (df[col].isna())\n",
    "    df.loc[mask, col] = 0\n",
    "\n",
    "# Passengers with 0 total spend might be CryoSleep\n",
    "mask = (df['CryoSleep'].isna()) & (df['TotalSpend'] == 0)\n",
    "df.loc[mask, 'CryoSleep'] = 1\n",
    "mask = (df['CryoSleep'].isna()) & (df['TotalSpend'] > 0)\n",
    "df.loc[mask, 'CryoSleep'] = 0\n",
    "\n",
    "# Fill remaining numericals with median\n",
    "num_cols_fill = df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols_fill:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill remaining categoricals with mode\n",
    "cat_cols_fill = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols_fill:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(f'Remaining nulls: {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================================================\n# 4.11 - Group Survival Features (key trick from titanicv2)\n# =========================================================\n\n# Only use train data for group survival to avoid leakage\ntrain_mask = df['is_train'] == 1\n\n# Group survival rate (leave-one-out to avoid leakage within train)\ntrain_df = df[train_mask].copy()\n\n# For groups with >1 member: compute transported rate of OTHER members\ngroup_sum = train_df.groupby('Group')[TARGET].transform('sum')\ngroup_count = train_df.groupby('Group')[TARGET].transform('count')\n\n# Leave-one-out: (sum - self) / (count - 1), safe division\ndenom = (group_count - 1).replace(0, np.nan)\ntrain_df['GroupSurvival_loo'] = (group_sum - train_df[TARGET]) / denom\ntrain_df['GroupSurvival_loo'] = train_df['GroupSurvival_loo'].fillna(0.5)  # no info for solo passengers\n\n# For test: use full group transported rate from train\ngroup_rate = train_df.groupby('Group')[TARGET].mean().to_dict()\n\ntest_df = df[~train_mask].copy()\ntest_df['GroupSurvival_loo'] = test_df['Group'].map(group_rate)\ntest_df['GroupSurvival_loo'] = test_df['GroupSurvival_loo'].fillna(0.5)\n\ndf = pd.concat([train_df, test_df], axis=0).sort_index()\n\n# Same for surname (family survival)\ntrain_df = df[train_mask].copy()\nfam_sum = train_df.groupby('Surname')[TARGET].transform('sum')\nfam_count = train_df.groupby('Surname')[TARGET].transform('count')\nfam_denom = (fam_count - 1).replace(0, np.nan)\ntrain_df['FamilySurvival_loo'] = (fam_sum - train_df[TARGET]) / fam_denom\ntrain_df['FamilySurvival_loo'] = train_df['FamilySurvival_loo'].fillna(0.5)\n\nfam_rate = train_df.groupby('Surname')[TARGET].mean().to_dict()\ntest_df = df[~train_mask].copy()\ntest_df['FamilySurvival_loo'] = test_df['Surname'].map(fam_rate)\ntest_df['FamilySurvival_loo'] = test_df['FamilySurvival_loo'].fillna(0.5)\n\ndf = pd.concat([train_df, test_df], axis=0).sort_index()\n\nprint('Group survival features added.')\nprint(f'GroupSurvival_loo stats: mean={df[\"GroupSurvival_loo\"].mean():.3f}')\nprint(f'FamilySurvival_loo stats: mean={df[\"FamilySurvival_loo\"].mean():.3f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final features\n",
    "drop_cols = ['PassengerId', 'Name', 'Cabin', 'Surname', 'is_train', TARGET,\n",
    "             'HomePlanet', 'Destination', 'Deck', 'Side', 'MaxSpendCategory']\n",
    "\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f'Number of features: {len(features)}')\n",
    "print(f'\\nFeatures:')\n",
    "for i, f in enumerate(sorted(features)):\n",
    "    print(f'  {i+1:2d}. {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split back to train/test\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[TARGET].values.astype(int)\n",
    "X_test = test_df[features].values\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}')\n",
    "print(f'Target: {np.mean(y):.4f} (should be ~0.50)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 20,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'n_estimators': 5000,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': SEED,\n",
    "}\n",
    "\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_lgb = np.zeros(len(X_test))\n",
    "fi_lgb = np.zeros(len(features))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    oof_lgb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_lgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    fi_lgb += model.feature_importances_ / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_lgb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "lgb_acc = accuracy_score(y, (oof_lgb > 0.5).astype(int))\n",
    "print(f'\\nLightGBM CV Accuracy: {lgb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "fi_df = pd.DataFrame({'feature': features, 'importance': fi_lgb})\n",
    "fi_df = fi_df.sort_values('importance', ascending=True).tail(25)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(fi_df['feature'], fi_df['importance'], color='steelblue')\n",
    "plt.title(f'LightGBM Feature Importance (Top 25) - CV Acc: {lgb_acc:.5f}')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modeling - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "xgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'logloss',\n    'max_depth': 6,\n    'learning_rate': 0.03,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'min_child_weight': 5,\n    'reg_alpha': 0.1,\n    'reg_lambda': 1.0,\n    'n_estimators': 5000,\n    'early_stopping_rounds': 200,\n    'tree_method': 'hist',\n    'random_state': SEED,\n    'verbosity': 0,\n}\n\noof_xgb = np.zeros(len(X))\ntest_xgb = np.zeros(len(X_test))\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n    X_tr, X_val = X[train_idx], X[val_idx]\n    y_tr, y_val = y[train_idx], y[val_idx]\n    \n    model = xgb.XGBClassifier(**xgb_params)\n    model.fit(\n        X_tr, y_tr,\n        eval_set=[(X_val, y_val)],\n        verbose=500\n    )\n    \n    oof_xgb[val_idx] = model.predict_proba(X_val)[:, 1]\n    test_xgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n    \n    fold_acc = accuracy_score(y_val, (oof_xgb[val_idx] > 0.5).astype(int))\n    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n\nxgb_acc = accuracy_score(y, (oof_xgb > 0.5).astype(int))\nprint(f'\\nXGBoost CV Accuracy: {xgb_acc:.5f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modeling - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_cb = np.zeros(len(X))\n",
    "test_cb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations=5000,\n",
    "        learning_rate=0.03,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=3.0,\n",
    "        subsample=0.8,\n",
    "        colsample_bylevel=0.8,\n",
    "        min_data_in_leaf=20,\n",
    "        random_seed=SEED,\n",
    "        verbose=500,\n",
    "        early_stopping_rounds=200,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=(X_val, y_val),\n",
    "    )\n",
    "    \n",
    "    oof_cb[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    test_cb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    fold_acc = accuracy_score(y_val, (oof_cb[val_idx] > 0.5).astype(int))\n",
    "    print(f'Fold {fold+1}/{N_FOLDS} - Accuracy: {fold_acc:.5f}')\n",
    "\n",
    "cb_acc = accuracy_score(y, (oof_cb > 0.5).astype(int))\n",
    "print(f'\\nCatBoost CV Accuracy: {cb_acc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Individual Model Scores ===')\n",
    "print(f'LightGBM: {lgb_acc:.5f}')\n",
    "print(f'XGBoost:  {xgb_acc:.5f}')\n",
    "print(f'CatBoost: {cb_acc:.5f}')\n",
    "print()\n",
    "\n",
    "# Simple average ensemble\n",
    "oof_avg = (oof_lgb + oof_xgb + oof_cb) / 3\n",
    "avg_acc = accuracy_score(y, (oof_avg > 0.5).astype(int))\n",
    "print(f'Simple Average Ensemble: {avg_acc:.5f}')\n",
    "\n",
    "# Weighted ensemble - find optimal weights via grid search\n",
    "best_acc = 0\n",
    "best_w = (1/3, 1/3, 1/3)\n",
    "\n",
    "for w1 in np.arange(0.1, 0.8, 0.05):\n",
    "    for w2 in np.arange(0.1, 0.8 - w1, 0.05):\n",
    "        w3 = 1 - w1 - w2\n",
    "        if w3 < 0.05:\n",
    "            continue\n",
    "        oof_w = w1 * oof_lgb + w2 * oof_xgb + w3 * oof_cb\n",
    "        acc = accuracy_score(y, (oof_w > 0.5).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_w = (w1, w2, w3)\n",
    "\n",
    "print(f'\\nOptimal Weighted Ensemble: {best_acc:.5f}')\n",
    "print(f'Weights: LGB={best_w[0]:.2f}, XGB={best_w[1]:.2f}, CB={best_w[2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank-based ensemble (more robust to score scale differences)\n",
    "oof_rank = (\n",
    "    rankdata(oof_lgb) + rankdata(oof_xgb) + rankdata(oof_cb)\n",
    ") / 3\n",
    "rank_threshold = np.median(oof_rank)  # since ~50/50 split\n",
    "rank_acc = accuracy_score(y, (oof_rank > rank_threshold).astype(int))\n",
    "print(f'Rank Ensemble: {rank_acc:.5f}')\n",
    "\n",
    "# Majority voting\n",
    "votes = (\n",
    "    (oof_lgb > 0.5).astype(int) + \n",
    "    (oof_xgb > 0.5).astype(int) + \n",
    "    (oof_cb > 0.5).astype(int)\n",
    ")\n",
    "vote_acc = accuracy_score(y, (votes >= 2).astype(int))\n",
    "print(f'Majority Voting: {vote_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best ensemble method\n",
    "ensemble_scores = {\n",
    "    'Simple Average': avg_acc,\n",
    "    'Weighted Average': best_acc,\n",
    "    'Rank Ensemble': rank_acc,\n",
    "    'Majority Voting': vote_acc,\n",
    "}\n",
    "\n",
    "best_method = max(ensemble_scores, key=ensemble_scores.get)\n",
    "print(f'\\nBest Ensemble Method: {best_method} ({ensemble_scores[best_method]:.5f})')\n",
    "\n",
    "# Generate final test predictions with best method\n",
    "if best_method == 'Simple Average':\n",
    "    final_proba = (test_lgb + test_xgb + test_cb) / 3\n",
    "elif best_method == 'Weighted Average':\n",
    "    final_proba = best_w[0] * test_lgb + best_w[1] * test_xgb + best_w[2] * test_cb\n",
    "elif best_method == 'Rank Ensemble':\n",
    "    final_proba = (rankdata(test_lgb) + rankdata(test_xgb) + rankdata(test_cb)) / 3\n",
    "    # Use same relative threshold\n",
    "elif best_method == 'Majority Voting':\n",
    "    final_votes = (\n",
    "        (test_lgb > 0.5).astype(int) + \n",
    "        (test_xgb > 0.5).astype(int) + \n",
    "        (test_cb > 0.5).astype(int)\n",
    "    )\n",
    "\n",
    "# Convert to binary predictions\n",
    "if best_method == 'Majority Voting':\n",
    "    final_preds = (final_votes >= 2)\n",
    "elif best_method == 'Rank Ensemble':\n",
    "    final_preds = (final_proba > np.median(final_proba))\n",
    "else:\n",
    "    final_preds = (final_proba > 0.5)\n",
    "\n",
    "print(f'\\nTest predictions: {final_preds.sum()} True / {len(final_preds) - final_preds.sum()} False')\n",
    "print(f'Ratio: {final_preds.mean():.4f} (should be ~0.50)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'].values,\n",
    "    'Transported': final_preds\n",
    "})\n",
    "\n",
    "# Ensure boolean format matches sample_submission\n",
    "submission['Transported'] = submission['Transported'].astype(bool)\n",
    "\n",
    "submission.to_csv('../submissions/submission.csv', index=False)\n",
    "\n",
    "print('Submission saved!')\n",
    "print(f'Shape: {submission.shape}')\n",
    "print(f'\\nDistribution:')\n",
    "print(submission['Transported'].value_counts(normalize=True))\n",
    "print(f'\\nFirst rows:')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation: compare with sample submission format\n",
    "assert submission.shape[0] == sample_sub.shape[0], 'Row count mismatch!'\n",
    "assert list(submission.columns) == list(sample_sub.columns), 'Column mismatch!'\n",
    "assert submission['Transported'].dtype == bool, 'Type mismatch!'\n",
    "print('Submission format validated!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('          SPACESHIP TITANIC - PIPELINE SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'\\nFeatures engineered: {len(features)}')\n",
    "print(f'CV Folds: {N_FOLDS}')\n",
    "print(f'\\n--- Model Scores (CV Accuracy) ---')\n",
    "print(f'  LightGBM:  {lgb_acc:.5f}')\n",
    "print(f'  XGBoost:   {xgb_acc:.5f}')\n",
    "print(f'  CatBoost:  {cb_acc:.5f}')\n",
    "print(f'\\n--- Ensemble Scores ---')\n",
    "for method, score in sorted(ensemble_scores.items(), key=lambda x: -x[1]):\n",
    "    marker = ' <-- BEST' if method == best_method else ''\n",
    "    print(f'  {method:20s}: {score:.5f}{marker}')\n",
    "print(f'\\n--- Submission ---')\n",
    "print(f'  File: ../submissions/submission.csv')\n",
    "print(f'  Rows: {submission.shape[0]}')\n",
    "print(f'  True ratio: {submission[\"Transported\"].mean():.4f}')\n",
    "print(f'\\n--- Next Steps ---')\n",
    "print('  1. Submit to Kaggle and check LB score')\n",
    "print('  2. Hyperparameter tuning with Optuna')\n",
    "print('  3. Add more interaction features')\n",
    "print('  4. Try neural network (TabNet, MLP)')\n",
    "print('  5. Pseudo-labeling with confident predictions')\n",
    "print('  6. Target encoding with proper CV')\n",
    "print('=' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}