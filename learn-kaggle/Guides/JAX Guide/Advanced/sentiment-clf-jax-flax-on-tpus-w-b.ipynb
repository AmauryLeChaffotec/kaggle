{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style='text-align: center'> Sentiment Classification - 1.6M Tweets + HuggingFace BERT + Jax/Flax TPUs + W&B Tracking </h1>\n\n<p style='text-align: center'>\nSentiment Classification on 1.6 Million tweets using Jax/Flax with TPUs using HuggingFace BERT and W&B Tracking!<br> \nI have used this <a href='https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification_flax.ipynb'> script</a> as a base and then modified it to work with this dataset.<br>\nI have also used Weights and Biases tracking to keep track of the training process and the experiments I will conduct.\n</p>","metadata":{}},{"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\"/></center><br>\n<p style=\"text-align:center\">WandB is a developer tool for companies turn deep learning research projects into deployed software by helping teams track their models, visualize model performance and easily automate training and improving models.\nWe will use their tools to log hyperparameters and output metrics from your runs, then visualize and compare results and quickly share findings with your colleagues.<br><br>We'll be using this to train our K Fold Cross Validation and gain better insights about our training. <br><br></p>\n\n![img](https://i.imgur.com/BGgfZj3.png)","metadata":{}},{"cell_type":"markdown","source":"**You can upvote this kernel, if you found it useful!**","metadata":{}},{"cell_type":"code","source":"%%capture\n! pip install --upgrade jax\n! pip install --upgrade jaxlib\n! pip install git+https://github.com/huggingface/transformers.git\n! pip install git+https://github.com/deepmind/optax.git\n! pip install flax\n! conda install -y -c conda-forge datasets\n! conda install -y importlib-metadata","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T09:10:33.814459Z","iopub.execute_input":"2021-08-03T09:10:33.814946Z","iopub.status.idle":"2021-08-03T09:30:02.425506Z","shell.execute_reply.started":"2021-08-03T09:10:33.814845Z","shell.execute_reply":"2021-08-03T09:30:02.423081Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%sh\npip install -q wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:30:02.430847Z","iopub.execute_input":"2021-08-03T09:30:02.431568Z","iopub.status.idle":"2021-08-03T09:30:14.161201Z","shell.execute_reply.started":"2021-08-03T09:30:02.431490Z","shell.execute_reply":"2021-08-03T09:30:14.159907Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.5.0 requires transformers<4.7,>=4.1, but you have transformers 4.10.0.dev0 which is incompatible.\nallennlp 2.5.0 requires wandb<0.11.0,>=0.10.0, but you have wandb 0.11.2 which is incompatible.\nWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nif 'TPU_NAME' in os.environ:\n    import requests\n    if 'TPU_DRIVER_MODE' not in globals():\n        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n        resp = requests.post(url)\n        TPU_DRIVER_MODE = 1\n\n    from jax.config import config\n    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n    config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n    print('Registered TPU:', config.FLAGS.jax_backend_target)\nelse:\n    print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:38:05.601804Z","iopub.execute_input":"2021-08-03T09:38:05.602313Z","iopub.status.idle":"2021-08-03T09:38:31.349734Z","shell.execute_reply.started":"2021-08-03T09:38:05.602261Z","shell.execute_reply":"2021-08-03T09:38:31.348873Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Registered TPU: grpc://10.0.0.2:8470\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nimport datasets\nfrom datasets import load_dataset, load_metric\n\nimport jax\nimport flax\nimport optax\nimport jaxlib\nimport jax.numpy as jnp\n\nfrom itertools import chain\nfrom typing import Callable\n\nfrom flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\nfrom flax.training import train_state\nfrom flax import traverse_util\n\nfrom transformers import AutoTokenizer, FlaxAutoModelForSequenceClassification, AutoConfig\n\nimport wandb\n\njax.local_devices()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:38:44.775375Z","iopub.execute_input":"2021-08-03T09:38:44.776037Z","iopub.status.idle":"2021-08-03T09:38:52.742152Z","shell.execute_reply.started":"2021-08-03T09:38:44.775976Z","shell.execute_reply":"2021-08-03T09:38:52.740719Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"},"metadata":{}}]},{"cell_type":"code","source":"class Config:\n    nb_epochs = 5\n    lr = 2e-5\n    per_device_bs = 32\n    num_labels = 2\n    model_name = 'bert-base-uncased'\n    total_batch_size = per_device_bs * jax.local_device_count()\n    tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:38:52.744570Z","iopub.execute_input":"2021-08-03T09:38:52.745036Z","iopub.status.idle":"2021-08-03T09:38:55.420719Z","shell.execute_reply.started":"2021-08-03T09:38:52.744990Z","shell.execute_reply":"2021-08-03T09:38:55.419411Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0182558d8442f68200ef2928ea495a"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ca4490e3df647338636eebef1f28523"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c8363360789430db530d0a0a18a20ff"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92b5349f7e494f86aff142cd80b89c33"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# You can add your W&B API token as Kaggle secret with the name \"WANDB_API_KEY\".\n# To get your W&B API token, visit https://wandb.ai/authorize\n\n# W&B Login\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# wb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n\n# wandb.login(key=wb_key)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    lr=2e-5,\n    model_name = 'bert-base-uncased',\n    epochs = 5,\n    split = 0.10,\n    per_device_bs = 32,\n    seed = 42,\n    num_labels = 2,\n    infra = \"Kaggle\",\n    competition = 'none',\n    _wandb_kernel = 'tanaym'\n)\n\nrun = wandb.init(project='jax_flax', \n                 config=CONFIG,\n                 group='bert',\n                 job_type='train',\n                 anonymous='allow'\n                )","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:39:19.097470Z","iopub.execute_input":"2021-08-03T09:39:19.098061Z","iopub.status.idle":"2021-08-03T09:39:34.640520Z","shell.execute_reply.started":"2021-08-03T09:39:19.098015Z","shell.execute_reply":"2021-08-03T09:39:34.639058Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: (1) Private W&B dashboard, no account required\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:  1\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Private W&B dashboard, no account required'\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.11.2<br/>\n                Syncing run <strong style=\"color:#cdcd00\">brisk-dream-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/anony-mouse-121867/jax_flax?apiKey=9d6719f84990bdcf2d4a9b8b54080f0eeb8f1733\" target=\"_blank\">https://wandb.ai/anony-mouse-121867/jax_flax?apiKey=9d6719f84990bdcf2d4a9b8b54080f0eeb8f1733</a><br/>\n                Run page: <a href=\"https://wandb.ai/anony-mouse-121867/jax_flax/runs/28s0ucnx?apiKey=9d6719f84990bdcf2d4a9b8b54080f0eeb8f1733\" target=\"_blank\">https://wandb.ai/anony-mouse-121867/jax_flax/runs/28s0ucnx?apiKey=9d6719f84990bdcf2d4a9b8b54080f0eeb8f1733</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210803_093927-28s0ucnx</code><br/><br/>\n            "},"metadata":{}}]},{"cell_type":"code","source":"def wandb_log(**kwargs):\n    \"\"\"\n    Logs a key-value pair to W&B\n    \"\"\"\n    for k, v in kwargs.items():\n        wandb.log({k: v})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-03T09:39:44.180321Z","iopub.execute_input":"2021-08-03T09:39:44.180913Z","iopub.status.idle":"2021-08-03T09:39:44.191387Z","shell.execute_reply.started":"2021-08-03T09:39:44.180855Z","shell.execute_reply":"2021-08-03T09:39:44.190024Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def simple_acc(preds, labels):\n    assert len(preds) == len(labels), \"Predictions and Labels matrices must be of same length\"\n    acc = (preds == labels).sum() / len(preds)\n    return acc\n\nclass ACCURACY(datasets.Metric):\n    def _info(self):\n        return datasets.MetricInfo(\n            description=\"Calculates Accuracy metric.\",\n            citation=\"TODO: _CITATION\",\n            inputs_description=\"_KWARGS_DESCRIPTION\",\n            features=datasets.Features({\n                'predictions': datasets.Value('int64'),\n                'references': datasets.Value('int64'),\n            }),\n            codebase_urls=[],\n            reference_urls=[],\n            format='numpy'\n        )\n\n    def _compute(self, predictions, references):\n        return {\"ACCURACY\": simple_acc(predictions, references)}\n    \nmetric = ACCURACY()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:39:53.358565Z","iopub.execute_input":"2021-08-03T09:39:53.359159Z","iopub.status.idle":"2021-08-03T09:39:53.376327Z","shell.execute_reply.started":"2021-08-03T09:39:53.359109Z","shell.execute_reply":"2021-08-03T09:39:53.374739Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def split_and_save(file_path: str, split: float = 0.10):\n    file = pd.read_csv(file_path, encoding='latin-1', names=['sentiment', 'id', 'date', 'query', 'username', 'text'])\n    file = file[['sentiment', 'text']]\n    file['sentiment'] = file['sentiment'].map({4: 1, 0: 0})\n    \n    file = file.sample(frac=1).reset_index(drop=True)\n    split_nb = int(len(file) * split)\n    \n    test_set = file[:split_nb].reset_index(drop=True)\n    train_set = file[split_nb:].reset_index(drop=True)\n    \n    train_set.to_csv(\"train_file.csv\", index=None)\n    test_set.to_csv(\"test_file.csv\", index=None)\n    print(\"Done.\")\n\nsplit_and_save(\"../input/sentiment140/training.1600000.processed.noemoticon.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:39:58.944020Z","iopub.execute_input":"2021-08-03T09:39:58.944568Z","iopub.status.idle":"2021-08-03T09:40:27.086438Z","shell.execute_reply.started":"2021-08-03T09:39:58.944510Z","shell.execute_reply":"2021-08-03T09:40:27.085240Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Done.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the training and testing files loaded in HF dataset format\nraw_train = load_dataset(\"csv\", data_files={'train': ['./train_file.csv']})\nraw_test = load_dataset(\"csv\", data_files={'test': ['./test_file.csv']})","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:40:46.871644Z","iopub.execute_input":"2021-08-03T09:40:46.872225Z","iopub.status.idle":"2021-08-03T09:40:52.286887Z","shell.execute_reply.started":"2021-08-03T09:40:46.872179Z","shell.execute_reply":"2021-08-03T09:40:52.285487Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-af255dc9caab3475/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-af255dc9caab3475/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\nDownloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-6b1cd4bbd25aec0e/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-6b1cd4bbd25aec0e/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(data):\n    \"\"\"\n    Preprocessing function\n    \"\"\"\n    texts = (data[\"text\"],)\n    processed = Config.tokenizer(*texts, padding=\"max_length\", max_length=128, truncation=True)\n    processed[\"labels\"] = data[\"sentiment\"]\n    return processed","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:40:55.515484Z","iopub.execute_input":"2021-08-03T09:40:55.515968Z","iopub.status.idle":"2021-08-03T09:40:55.523730Z","shell.execute_reply.started":"2021-08-03T09:40:55.515928Z","shell.execute_reply":"2021-08-03T09:40:55.522532Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_dataset = raw_train.map(preprocess_function, batched=True, remove_columns=raw_train[\"train\"].column_names)\ntest_dataset = raw_test.map(preprocess_function, batched=True, remove_columns=raw_test['test'].column_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:40:58.217561Z","iopub.execute_input":"2021-08-03T09:40:58.218120Z","iopub.status.idle":"2021-08-03T09:44:38.382793Z","shell.execute_reply.started":"2021-08-03T09:40:58.218069Z","shell.execute_reply":"2021-08-03T09:44:38.381436Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1440.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d91082a72fd45b4be2006a06bf0d892"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=160.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01b0a217f4704e1c857bff82b671a9ca"}},"metadata":{}},{"name":"stdout","text":"\nCPU times: user 8min 13s, sys: 1min 14s, total: 9min 28s\nWall time: 3min 40s\n","output_type":"stream"}]},{"cell_type":"code","source":"train = train_dataset['train']\nvalid = test_dataset['test']\nprint(len(train), len(valid))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:44:38.385255Z","iopub.execute_input":"2021-08-03T09:44:38.385753Z","iopub.status.idle":"2021-08-03T09:44:38.398150Z","shell.execute_reply.started":"2021-08-03T09:44:38.385707Z","shell.execute_reply":"2021-08-03T09:44:38.395983Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"1440000 160000\n","output_type":"stream"}]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(Config.model_name, num_labels=Config.num_labels)\nmodel = FlaxAutoModelForSequenceClassification.from_pretrained(Config.model_name, config=config, seed=42)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:44:38.400629Z","iopub.execute_input":"2021-08-03T09:44:38.401246Z","iopub.status.idle":"2021-08-03T09:45:11.046983Z","shell.execute_reply.started":"2021-08-03T09:44:38.401170Z","shell.execute_reply":"2021-08-03T09:45:11.045599Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438064459.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0efe478dd974b76b97d98b57c52f27f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing FlaxBertForSequenceClassification: {('cls', 'predictions', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'scale'), ('cls', 'predictions', 'transform', 'dense', 'kernel'), ('cls', 'predictions', 'transform', 'dense', 'bias'), ('cls', 'predictions', 'transform', 'LayerNorm', 'bias')}\n- This IS expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing FlaxBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of FlaxBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('bert', 'pooler', 'dense', 'bias'), ('classifier', 'kernel'), ('bert', 'pooler', 'dense', 'kernel'), ('classifier', 'bias')}\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_train_steps = len(train) // Config.total_batch_size * Config.nb_epochs\nlearning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=Config.lr, pct_start=0.1)\nprint(\"The number of train steps (all the epochs) is\", num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:11.049089Z","iopub.execute_input":"2021-08-03T09:45:11.049793Z","iopub.status.idle":"2021-08-03T09:45:11.960548Z","shell.execute_reply.started":"2021-08-03T09:45:11.049729Z","shell.execute_reply":"2021-08-03T09:45:11.959382Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"The number of train steps (all the epochs) is 28125\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optax.adamw(learning_rate=Config.lr, b1=0.9, b2=0.999, eps=1e-6, weight_decay=1e-2)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:11.962374Z","iopub.execute_input":"2021-08-03T09:45:11.962848Z","iopub.status.idle":"2021-08-03T09:45:11.971036Z","shell.execute_reply.started":"2021-08-03T09:45:11.962798Z","shell.execute_reply":"2021-08-03T09:45:11.969649Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def loss_fn(logits, targets):\n    loss = optax.softmax_cross_entropy(logits, onehot(targets, num_classes=Config.num_labels))\n    return jnp.mean(loss)\ndef eval_fn(logits):\n    return logits.argmax(-1)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:11.975048Z","iopub.execute_input":"2021-08-03T09:45:11.975612Z","iopub.status.idle":"2021-08-03T09:45:11.989862Z","shell.execute_reply.started":"2021-08-03T09:45:11.975553Z","shell.execute_reply":"2021-08-03T09:45:11.988497Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class TrainState(train_state.TrainState):\n    eval_function: Callable = flax.struct.field(pytree_node=False)\n    loss_function: Callable = flax.struct.field(pytree_node=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:11.991738Z","iopub.execute_input":"2021-08-03T09:45:11.992618Z","iopub.status.idle":"2021-08-03T09:45:12.009394Z","shell.execute_reply.started":"2021-08-03T09:45:11.992560Z","shell.execute_reply":"2021-08-03T09:45:12.007125Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"state = TrainState.create(\n    apply_fn = model.__call__,\n    params = model.params,\n    tx = optimizer,\n    eval_function=eval_fn,\n    loss_function=loss_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:12.013298Z","iopub.execute_input":"2021-08-03T09:45:12.013909Z","iopub.status.idle":"2021-08-03T09:45:13.633755Z","shell.execute_reply.started":"2021-08-03T09:45:12.013822Z","shell.execute_reply":"2021-08-03T09:45:13.632473Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_step(state, batch, dropout_rng):\n    targets = batch.pop(\"labels\")\n    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n    \n    def loss_function(params):\n        logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n        loss = state.loss_function(logits, targets)\n        return loss\n    \n    grad_fn = jax.value_and_grad(loss_function)\n    loss, grad = grad_fn(state.params)\n    grad = jax.lax.pmean(grad, \"batch\")\n    new_state = state.apply_gradients(grads=grad)\n    metrics = jax.lax.pmean({'loss': loss, 'learning_rate': learning_rate_function(state.step)}, axis_name='batch')\n    \n    return new_state, metrics, new_dropout_rng","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:13.635889Z","iopub.execute_input":"2021-08-03T09:45:13.636324Z","iopub.status.idle":"2021-08-03T09:45:13.648076Z","shell.execute_reply.started":"2021-08-03T09:45:13.636264Z","shell.execute_reply":"2021-08-03T09:45:13.646891Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:13.649724Z","iopub.execute_input":"2021-08-03T09:45:13.650119Z","iopub.status.idle":"2021-08-03T09:45:15.274403Z","shell.execute_reply.started":"2021-08-03T09:45:13.650080Z","shell.execute_reply":"2021-08-03T09:45:15.273108Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def eval_step(state, batch):\n    logits = state.apply_fn(**batch, params=state.params, train=False)[0]\n    return state.eval_function(logits)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.276244Z","iopub.execute_input":"2021-08-03T09:45:15.276666Z","iopub.status.idle":"2021-08-03T09:45:15.288733Z","shell.execute_reply.started":"2021-08-03T09:45:15.276628Z","shell.execute_reply":"2021-08-03T09:45:15.287422Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.291956Z","iopub.execute_input":"2021-08-03T09:45:15.292702Z","iopub.status.idle":"2021-08-03T09:45:15.302661Z","shell.execute_reply.started":"2021-08-03T09:45:15.292653Z","shell.execute_reply":"2021-08-03T09:45:15.301142Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def sentimentTrainDataLoader(rng, dataset, batch_size):\n    steps_per_epoch = len(dataset) // batch_size\n    perms = jax.random.permutation(rng, len(dataset))\n    perms = perms[: steps_per_epoch * batch_size]  # Skip incomplete batch.\n    perms = perms.reshape((steps_per_epoch, batch_size))\n\n    for perm in perms:\n        batch = dataset[perm]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n\n        yield batch","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.304601Z","iopub.execute_input":"2021-08-03T09:45:15.305117Z","iopub.status.idle":"2021-08-03T09:45:15.316862Z","shell.execute_reply.started":"2021-08-03T09:45:15.305061Z","shell.execute_reply":"2021-08-03T09:45:15.315550Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def sentimentEvalDataLoader(dataset, batch_size):\n    for i in range(len(dataset) // batch_size):\n        batch = dataset[i * batch_size : (i + 1) * batch_size]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n\n        yield batch","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.318569Z","iopub.execute_input":"2021-08-03T09:45:15.318962Z","iopub.status.idle":"2021-08-03T09:45:15.336358Z","shell.execute_reply.started":"2021-08-03T09:45:15.318925Z","shell.execute_reply":"2021-08-03T09:45:15.334721Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"state = flax.jax_utils.replicate(state)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.338190Z","iopub.execute_input":"2021-08-03T09:45:15.338599Z","iopub.status.idle":"2021-08-03T09:45:15.939871Z","shell.execute_reply.started":"2021-08-03T09:45:15.338559Z","shell.execute_reply":"2021-08-03T09:45:15.938518Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/jax/lib/xla_bridge.py:365: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n  \"jax.host_count has been renamed to jax.process_count. This alias \"\n/opt/conda/lib/python3.7/site-packages/jax/lib/xla_bridge.py:352: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n  \"jax.host_id has been renamed to jax.process_index. This alias \"\n","output_type":"stream"}]},{"cell_type":"code","source":"rng = jax.random.PRNGKey(42)\ndropout_rngs = jax.random.split(rng, jax.local_device_count())","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:15.941703Z","iopub.execute_input":"2021-08-03T09:45:15.942122Z","iopub.status.idle":"2021-08-03T09:45:16.999428Z","shell.execute_reply.started":"2021-08-03T09:45:15.942079Z","shell.execute_reply":"2021-08-03T09:45:16.998359Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for i, epoch in enumerate(tqdm(range(1, Config.nb_epochs + 1), desc=f\"Epoch...\", position=0, leave=True)):\n    rng, input_rng = jax.random.split(rng)\n\n    # train\n    with tqdm(total=len(train) // Config.total_batch_size, desc=\"Training...\", leave=False) as progress_bar_train:\n        for batch in sentimentTrainDataLoader(input_rng, train, Config.total_batch_size):\n            state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n            progress_bar_train.update(1)\n\n    # evaluate\n    with tqdm(total=len(valid) // Config.total_batch_size, desc=\"Evaluating...\", leave=False) as progress_bar_eval:\n        for batch in sentimentEvalDataLoader(valid, Config.total_batch_size):\n            labels = batch.pop(\"labels\")\n            predictions = parallel_eval_step(state, batch)\n            metric.add_batch(predictions=chain(*predictions), references=chain(*labels))\n            progress_bar_eval.update(1)\n\n    eval_metric = metric.compute()\n\n    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n    eval_score = round(list(eval_metric.values())[0], 3)\n    metric_name = list(eval_metric.keys())[0]\n    \n    wandb_log(\n        train_loss=loss,\n        valid_acc=eval_score\n    )\n    print(f\"{i+1}/{Config.nb_epochs} | Train loss: {loss} | Eval {metric_name}: {eval_score}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:45:17.002683Z","iopub.execute_input":"2021-08-03T09:45:17.003231Z","iopub.status.idle":"2021-08-03T13:40:41.837063Z","shell.execute_reply.started":"2021-08-03T09:45:17.003179Z","shell.execute_reply":"2021-08-03T13:40:41.836238Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Epoch...', max=5.0, style=ProgressStyle(description_width…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e6b14ff7f943db9964adb3a142d2b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Training...', max=5625.0, style=ProgressStyle(description…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Evaluating...', max=625.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"1/5 | Train loss: 0.257 | Eval ACCURACY: 0.869\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Training...', max=5625.0, style=ProgressStyle(description…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Evaluating...', max=625.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"2/5 | Train loss: 0.308 | Eval ACCURACY: 0.875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Training...', max=5625.0, style=ProgressStyle(description…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Evaluating...', max=625.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"3/5 | Train loss: 0.3 | Eval ACCURACY: 0.875\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Training...', max=5625.0, style=ProgressStyle(description…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Evaluating...', max=625.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"4/5 | Train loss: 0.234 | Eval ACCURACY: 0.872\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Training...', max=5625.0, style=ProgressStyle(description…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Evaluating...', max=625.0, style=ProgressStyle(descriptio…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"5/5 | Train loss: 0.192 | Eval ACCURACY: 0.871\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### [Check out the W&B Run Page here $\\rightarrow$](https://wandb.ai/anony-mouse-121867/jax_flax/runs/28s0ucnx)\n\n![img](https://i.imgur.com/YnmHupI.gif)","metadata":{}}]}