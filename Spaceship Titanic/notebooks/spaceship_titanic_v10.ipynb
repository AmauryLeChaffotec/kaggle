{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic - V10 (Multi-Seed + Threshold + Blend)\n",
    "\n",
    "**V5 = BEST LB (0.80874)**. Features et params sont au sweet spot. On exploite 3 leviers \"gratuits\" :\n",
    "\n",
    "1. **Multi-seed averaging** : V5 entraîné avec 5 seeds → réduit la variance des prédictions\n",
    "2. **Threshold optimization** : trouver le seuil optimal (≠ 0.50) sur les OOF predictions\n",
    "3. **Submission blending** : vote majoritaire entre V5, V8, et V10 multi-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 10\n",
    "TARGET = 'Transported'\n",
    "SEEDS = [42, 123, 456, 789, 2024]\n",
    "\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "print(f'V10 Setup complete. Seeds: {SEEDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print(f'Train: {train.shape}, Test: {test.shape}')\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test[TARGET] = np.nan\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "spend_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "print(f'Combined: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (V5 identique — 32 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V2 Feature Engineering (IDENTICAL) ===\n",
    "df['_Group'] = df['PassengerId'].str.split('_').str[0].astype(int)\n",
    "df['GroupSize'] = df.groupby('_Group')['PassengerId'].transform('count')\n",
    "df['IsAlone'] = (df['GroupSize'] == 1).astype(int)\n",
    "\n",
    "df['Deck'] = df['Cabin'].str.split('/').str[0]\n",
    "df['CabinNum'] = df['Cabin'].str.split('/').str[1].astype(float)\n",
    "df['Side'] = df['Cabin'].str.split('/').str[2]\n",
    "df['CabinRegion'] = (df['CabinNum'] // 100).astype(float)\n",
    "\n",
    "df['Surname'] = df['Name'].str.split().str[-1]\n",
    "df['FamilySize'] = df.groupby('Surname')['PassengerId'].transform('count')\n",
    "df.loc[df['Surname'].isna(), 'FamilySize'] = 1\n",
    "\n",
    "df['CryoSleep'] = df['CryoSleep'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "df['VIP'] = df['VIP'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "\n",
    "# Imputation\n",
    "for col in spend_cols:\n",
    "    mask = (df['CryoSleep'] == 1) & (df[col].isna())\n",
    "    df.loc[mask, col] = 0\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) == 0)\n",
    "df.loc[mask, 'CryoSleep'] = 1\n",
    "mask = (df['CryoSleep'].isna()) & (df[spend_cols].sum(axis=1) > 0)\n",
    "df.loc[mask, 'CryoSleep'] = 0\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Spending features\n",
    "df['TotalSpend'] = df[spend_cols].sum(axis=1)\n",
    "df['TotalSpend_log'] = np.log1p(df['TotalSpend'])\n",
    "df['NoSpend'] = (df['TotalSpend'] == 0).astype(int)\n",
    "df['NumServicesUsed'] = (df[spend_cols] > 0).sum(axis=1)\n",
    "for col in spend_cols:\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "df['LuxurySpend'] = np.log1p(df['Spa'] + df['VRDeck'] + df['RoomService'])\n",
    "df['BasicSpend'] = np.log1p(df['FoodCourt'] + df['ShoppingMall'])\n",
    "\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 5, 12, 18, 30, 50, 80], labels=[0,1,2,3,4,5]).astype(float)\n",
    "df['IsChild'] = (df['Age'] < 18).astype(float)\n",
    "df['CryoSleep_NoSpend'] = ((df['CryoSleep'] == 1) & (df['TotalSpend'] == 0)).astype(int)\n",
    "\n",
    "df['GroupSpend_mean'] = df.groupby('_Group')['TotalSpend'].transform('mean')\n",
    "df['GroupSpend_mean_log'] = np.log1p(df['GroupSpend_mean'])\n",
    "\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    le = LabelEncoder()\n",
    "    df[col + '_le'] = le.fit_transform(df[col].astype(str))\n",
    "for col in ['HomePlanet', 'Destination', 'Deck', 'Side']:\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    df[col + '_freq'] = df[col].map(freq)\n",
    "\n",
    "print('V2 features done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TARGET ENCODING (V5 identique) ===\n",
    "te_cols = ['HomePlanet', 'Destination', 'Deck']\n",
    "SMOOTHING = 20\n",
    "\n",
    "train_idx = df[df['is_train'] == 1].index\n",
    "test_idx = df[df['is_train'] == 0].index\n",
    "\n",
    "y_for_te = df.loc[train_idx, TARGET].map({True: 1.0, False: 0.0, 1: 1.0, 0: 0.0}).astype(float)\n",
    "df.loc[train_idx, '_target_float'] = y_for_te.values\n",
    "global_mean = float(y_for_te.mean())\n",
    "\n",
    "kf_te = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "for col in te_cols:\n",
    "    col_te = f'{col}_te'\n",
    "    df[col_te] = global_mean\n",
    "    for fold_train, fold_val in kf_te.split(train_idx, y_for_te):\n",
    "        fold_train_idx = train_idx[fold_train]\n",
    "        fold_val_idx = train_idx[fold_val]\n",
    "        stats = df.loc[fold_train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "        stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "        mapped = df.loc[fold_val_idx, col].map(stats['te']).fillna(global_mean)\n",
    "        df.loc[fold_val_idx, col_te] = mapped.values\n",
    "    stats = df.loc[train_idx].groupby(col)['_target_float'].agg(['mean', 'count'])\n",
    "    stats['te'] = (stats['count'] * stats['mean'] + SMOOTHING * global_mean) / (stats['count'] + SMOOTHING)\n",
    "    mapped = df.loc[test_idx, col].map(stats['te']).fillna(global_mean)\n",
    "    df.loc[test_idx, col_te] = mapped.values\n",
    "\n",
    "df.drop('_target_float', axis=1, inplace=True)\n",
    "print('Target encoding done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURES (V5: 32 features) ===\n",
    "drop_cols = [\n",
    "    'PassengerId', 'Name', 'Cabin', 'Surname', 'is_train', TARGET,\n",
    "    'HomePlanet', 'Destination', 'Deck', 'Side',\n",
    "    '_Group', 'CabinNum',\n",
    "    'TotalSpend', 'GroupSpend_mean',\n",
    "] + spend_cols\n",
    "\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print(f'Features: {len(features)} (should be 32)')\n",
    "\n",
    "train_df = df[df['is_train'] == 1].copy()\n",
    "test_df = df[df['is_train'] == 0].copy()\n",
    "\n",
    "X = train_df[features].values\n",
    "y = train_df[TARGET].astype(int).values\n",
    "X_test = test_df[features].values\n",
    "\n",
    "print(f'X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Multi-Seed Averaging (5 seeds × 3 models × 10 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 manual params\n",
    "lgb_base_params = {\n",
    "    'objective': 'binary', 'metric': 'binary_logloss', 'boosting_type': 'gbdt',\n",
    "    'num_leaves': 20, 'learning_rate': 0.03, 'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7, 'bagging_freq': 5, 'min_child_samples': 30,\n",
    "    'reg_alpha': 0.5, 'reg_lambda': 2.0, 'max_depth': 5,\n",
    "    'n_estimators': 5000, 'verbose': -1, 'n_jobs': -1,\n",
    "}\n",
    "\n",
    "xgb_base_params = {\n",
    "    'objective': 'binary:logistic', 'eval_metric': 'logloss',\n",
    "    'max_depth': 4, 'learning_rate': 0.03, 'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7, 'min_child_weight': 10,\n",
    "    'reg_alpha': 0.5, 'reg_lambda': 2.0, 'gamma': 0.1,\n",
    "    'n_estimators': 5000, 'early_stopping_rounds': 200,\n",
    "    'tree_method': 'hist', 'verbosity': 0,\n",
    "}\n",
    "\n",
    "cb_base_params = {\n",
    "    'iterations': 5000, 'learning_rate': 0.03, 'depth': 4,\n",
    "    'l2_leaf_reg': 5.0, 'subsample': 0.7, 'colsample_bylevel': 0.7,\n",
    "    'min_data_in_leaf': 30, 'verbose': 0, 'early_stopping_rounds': 200,\n",
    "    'task_type': 'CPU',\n",
    "}\n",
    "\n",
    "print('Model params ready (V2 manual, proven on LB).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MULTI-SEED TRAINING ===\n",
    "\n",
    "all_oof_lgb = []\n",
    "all_oof_xgb = []\n",
    "all_oof_cb = []\n",
    "all_test_lgb = []\n",
    "all_test_xgb = []\n",
    "all_test_cb = []\n",
    "\n",
    "for seed_i, seed in enumerate(SEEDS):\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'SEED {seed_i+1}/{len(SEEDS)}: {seed}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # --- LightGBM ---\n",
    "    oof_lgb = np.zeros(len(X))\n",
    "    test_lgb = np.zeros(len(X_test))\n",
    "    lgb_params = {**lgb_base_params, 'random_state': seed}\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        model = lgb.LGBMClassifier(**lgb_params)\n",
    "        model.fit(X[tr_idx], y[tr_idx], eval_set=[(X[val_idx], y[val_idx])],\n",
    "                  callbacks=[lgb.early_stopping(200, verbose=False), lgb.log_evaluation(0)])\n",
    "        oof_lgb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "        test_lgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    lgb_acc = accuracy_score(y, (oof_lgb > 0.5).astype(int))\n",
    "    print(f'  LGB seed={seed}: CV {lgb_acc:.5f}')\n",
    "    all_oof_lgb.append(oof_lgb)\n",
    "    all_test_lgb.append(test_lgb)\n",
    "    \n",
    "    # --- XGBoost ---\n",
    "    oof_xgb = np.zeros(len(X))\n",
    "    test_xgb = np.zeros(len(X_test))\n",
    "    xgb_params = {**xgb_base_params, 'random_state': seed}\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        model = xgb.XGBClassifier(**xgb_params)\n",
    "        model.fit(X[tr_idx], y[tr_idx], eval_set=[(X[val_idx], y[val_idx])], verbose=0)\n",
    "        oof_xgb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "        test_xgb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    xgb_acc = accuracy_score(y, (oof_xgb > 0.5).astype(int))\n",
    "    print(f'  XGB seed={seed}: CV {xgb_acc:.5f}')\n",
    "    all_oof_xgb.append(oof_xgb)\n",
    "    all_test_xgb.append(test_xgb)\n",
    "    \n",
    "    # --- CatBoost ---\n",
    "    oof_cb = np.zeros(len(X))\n",
    "    test_cb = np.zeros(len(X_test))\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        model = CatBoostClassifier(**cb_base_params, random_seed=seed)\n",
    "        model.fit(X[tr_idx], y[tr_idx], eval_set=(X[val_idx], y[val_idx]))\n",
    "        oof_cb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "        test_cb += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
    "    \n",
    "    cb_acc = accuracy_score(y, (oof_cb > 0.5).astype(int))\n",
    "    print(f'  CB  seed={seed}: CV {cb_acc:.5f}')\n",
    "    all_oof_cb.append(oof_cb)\n",
    "    all_test_cb.append(test_cb)\n",
    "\n",
    "print(f'\\nMulti-seed training complete: {len(SEEDS)} seeds x 3 models x {N_FOLDS} folds = {len(SEEDS)*3*N_FOLDS} models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MULTI-SEED AVERAGING ===\n",
    "\n",
    "# Average across seeds for each model\n",
    "oof_lgb_ms = np.mean(all_oof_lgb, axis=0)\n",
    "oof_xgb_ms = np.mean(all_oof_xgb, axis=0)\n",
    "oof_cb_ms = np.mean(all_oof_cb, axis=0)\n",
    "\n",
    "test_lgb_ms = np.mean(all_test_lgb, axis=0)\n",
    "test_xgb_ms = np.mean(all_test_xgb, axis=0)\n",
    "test_cb_ms = np.mean(all_test_cb, axis=0)\n",
    "\n",
    "# Single-seed (seed=42) for comparison = first element\n",
    "lgb_single = accuracy_score(y, (all_oof_lgb[0] > 0.5).astype(int))\n",
    "xgb_single = accuracy_score(y, (all_oof_xgb[0] > 0.5).astype(int))\n",
    "cb_single = accuracy_score(y, (all_oof_cb[0] > 0.5).astype(int))\n",
    "\n",
    "lgb_ms_acc = accuracy_score(y, (oof_lgb_ms > 0.5).astype(int))\n",
    "xgb_ms_acc = accuracy_score(y, (oof_xgb_ms > 0.5).astype(int))\n",
    "cb_ms_acc = accuracy_score(y, (oof_cb_ms > 0.5).astype(int))\n",
    "\n",
    "print('=== MULTI-SEED vs SINGLE-SEED ===')\n",
    "print(f'LGB: single={lgb_single:.5f} → multi-seed={lgb_ms_acc:.5f} ({\"+\" if lgb_ms_acc >= lgb_single else \"\"}{lgb_ms_acc - lgb_single:+.5f})')\n",
    "print(f'XGB: single={xgb_single:.5f} → multi-seed={xgb_ms_acc:.5f} ({\"+\" if xgb_ms_acc >= xgb_single else \"\"}{xgb_ms_acc - xgb_single:+.5f})')\n",
    "print(f'CB:  single={cb_single:.5f} → multi-seed={cb_ms_acc:.5f} ({\"+\" if cb_ms_acc >= cb_single else \"\"}{cb_ms_acc - cb_single:+.5f})')\n",
    "\n",
    "# 3-model ensemble (multi-seed averaged)\n",
    "oof_ensemble_ms = (oof_lgb_ms + oof_xgb_ms + oof_cb_ms) / 3\n",
    "test_ensemble_ms = (test_lgb_ms + test_xgb_ms + test_cb_ms) / 3\n",
    "\n",
    "# Single-seed ensemble for comparison\n",
    "oof_ensemble_single = (all_oof_lgb[0] + all_oof_xgb[0] + all_oof_cb[0]) / 3\n",
    "single_acc = accuracy_score(y, (oof_ensemble_single > 0.5).astype(int))\n",
    "ms_acc = accuracy_score(y, (oof_ensemble_ms > 0.5).astype(int))\n",
    "\n",
    "print(f'\\nEnsemble: single-seed={single_acc:.5f} → multi-seed={ms_acc:.5f} ({ms_acc - single_acc:+.5f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === THRESHOLD OPTIMIZATION on multi-seed OOF ===\n",
    "\n",
    "thresholds = np.arange(0.440, 0.560, 0.001)\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (oof_ensemble_ms > t).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    scores.append(acc)\n",
    "\n",
    "scores = np.array(scores)\n",
    "best_idx = np.argmax(scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_acc = scores[best_idx]\n",
    "\n",
    "# Also check per-model thresholds\n",
    "for name, oof in [('LGB', oof_lgb_ms), ('XGB', oof_xgb_ms), ('CB', oof_cb_ms), ('Ensemble', oof_ensemble_ms)]:\n",
    "    best_t = 0.5\n",
    "    best_a = 0\n",
    "    for t in np.arange(0.440, 0.560, 0.001):\n",
    "        a = accuracy_score(y, (oof > t).astype(int))\n",
    "        if a > best_a:\n",
    "            best_a = a\n",
    "            best_t = t\n",
    "    default_a = accuracy_score(y, (oof > 0.5).astype(int))\n",
    "    print(f'{name:10s}: default(0.500)={default_a:.5f}  best(t={best_t:.3f})={best_a:.5f}  gain={best_a-default_a:+.5f}')\n",
    "\n",
    "print(f'\\nOptimal threshold for ensemble: {best_threshold:.3f} → accuracy {best_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold sensitivity\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(thresholds, scores, 'b-', linewidth=1.5)\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7, label='Default (0.500)')\n",
    "ax.axvline(x=best_threshold, color='red', linestyle='--', alpha=0.7, label=f'Optimal ({best_threshold:.3f})')\n",
    "ax.scatter([best_threshold], [best_acc], color='red', s=100, zorder=5)\n",
    "ax.scatter([0.5], [accuracy_score(y, (oof_ensemble_ms > 0.5).astype(int))], color='gray', s=100, zorder=5)\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('CV Accuracy')\n",
    "ax.set_title(f'Threshold Optimization (Multi-Seed Ensemble)\\nBest: t={best_threshold:.3f}, acc={best_acc:.5f}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# How many predictions change?\n",
    "preds_default = (oof_ensemble_ms > 0.5).astype(int)\n",
    "preds_optimal = (oof_ensemble_ms > best_threshold).astype(int)\n",
    "n_changed = (preds_default != preds_optimal).sum()\n",
    "print(f'Predictions changed by threshold shift: {n_changed} ({n_changed/len(y)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Submission Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD EXISTING BEST SUBMISSIONS ===\n",
    "sub_v5 = pd.read_csv('../submissions/submission_v5.csv')\n",
    "sub_v8 = pd.read_csv('../submissions/submission_v8.csv')  # 5-model, LB 0.80851\n",
    "\n",
    "# Convert to int\n",
    "v5_preds = sub_v5['Transported'].astype(int).values\n",
    "v8_preds = sub_v8['Transported'].astype(int).values\n",
    "\n",
    "# V10 predictions (multi-seed, default threshold)\n",
    "v10_preds_default = (test_ensemble_ms > 0.5).astype(int)\n",
    "v10_preds_optimal = (test_ensemble_ms > best_threshold).astype(int)\n",
    "\n",
    "print('=== SUBMISSION COMPARISON ===')\n",
    "print(f'V5  (LB 0.80874): True={v5_preds.sum()}, False={len(v5_preds)-v5_preds.sum()}')\n",
    "print(f'V8  (LB 0.80851): True={v8_preds.sum()}, False={len(v8_preds)-v8_preds.sum()}')\n",
    "print(f'V10 (t=0.500):    True={v10_preds_default.sum()}, False={len(v10_preds_default)-v10_preds_default.sum()}')\n",
    "print(f'V10 (t={best_threshold:.3f}):    True={v10_preds_optimal.sum()}, False={len(v10_preds_optimal)-v10_preds_optimal.sum()}')\n",
    "\n",
    "# Pairwise agreement\n",
    "print(f'\\n=== PAIRWISE AGREEMENT ===')\n",
    "print(f'V5  vs V8:  {(v5_preds == v8_preds).mean():.4f} ({(v5_preds != v8_preds).sum()} diffs)')\n",
    "print(f'V5  vs V10: {(v5_preds == v10_preds_default).mean():.4f} ({(v5_preds != v10_preds_default).sum()} diffs)')\n",
    "print(f'V8  vs V10: {(v8_preds == v10_preds_default).mean():.4f} ({(v8_preds != v10_preds_default).sum()} diffs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAJORITY VOTING BLENDS ===\n",
    "\n",
    "# Blend 1: V5 + V8 + V10(default) — 3-way majority vote\n",
    "votes_3way = v5_preds + v8_preds + v10_preds_default\n",
    "blend_3way = (votes_3way >= 2).astype(int)  # majority = 2 out of 3\n",
    "\n",
    "# Blend 2: V5 + V8 + V10(optimal threshold)\n",
    "votes_3way_opt = v5_preds + v8_preds + v10_preds_optimal\n",
    "blend_3way_opt = (votes_3way_opt >= 2).astype(int)\n",
    "\n",
    "# How different from V5?\n",
    "print('=== MAJORITY VOTE BLENDS ===')\n",
    "diff_3way = (blend_3way != v5_preds).sum()\n",
    "diff_3way_opt = (blend_3way_opt != v5_preds).sum()\n",
    "print(f'Blend(V5+V8+V10 default):  {diff_3way} diffs from V5 ({diff_3way/len(v5_preds)*100:.1f}%)')\n",
    "print(f'Blend(V5+V8+V10 optimal):  {diff_3way_opt} diffs from V5 ({diff_3way_opt/len(v5_preds)*100:.1f}%)')\n",
    "\n",
    "# Where do all 3 agree vs disagree?\n",
    "all_agree = (votes_3way == 0) | (votes_3way == 3)\n",
    "print(f'\\nAll 3 agree: {all_agree.sum()} ({all_agree.mean()*100:.1f}%)')\n",
    "print(f'Disagreement: {(~all_agree).sum()} ({(~all_agree).mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate All Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(preds_int, filename, description):\n",
    "    sub = pd.DataFrame({\n",
    "        'PassengerId': test_df['PassengerId'].values,\n",
    "        'Transported': preds_int.astype(bool)\n",
    "    })\n",
    "    sub.to_csv(f'../submissions/{filename}', index=False)\n",
    "    assert sub.shape[0] == sample_sub.shape[0]\n",
    "    assert list(sub.columns) == list(sample_sub.columns)\n",
    "    print(f'{filename:40s} | {description}')\n",
    "    print(f'  True={preds_int.sum()}, False={len(preds_int)-preds_int.sum()}, Ratio={preds_int.mean():.4f}')\n",
    "    return sub\n",
    "\n",
    "print('=== GENERATING SUBMISSIONS ===')\n",
    "print()\n",
    "\n",
    "# 1. Multi-seed, default threshold\n",
    "save_submission(v10_preds_default, 'submission_v10_multiseed.csv',\n",
    "                f'Multi-seed(5 seeds), t=0.500, CV={ms_acc:.5f}')\n",
    "print()\n",
    "\n",
    "# 2. Multi-seed, optimal threshold\n",
    "save_submission(v10_preds_optimal, 'submission_v10_optimal_t.csv',\n",
    "                f'Multi-seed(5 seeds), t={best_threshold:.3f}, CV={best_acc:.5f}')\n",
    "print()\n",
    "\n",
    "# 3. Majority vote blend (V5 + V8 + V10)\n",
    "save_submission(blend_3way, 'submission_v10_blend.csv',\n",
    "                'Majority vote: V5 + V8 + V10(default)')\n",
    "print()\n",
    "\n",
    "# 4. Majority vote blend with optimal threshold\n",
    "save_submission(blend_3way_opt, 'submission_v10_blend_opt.csv',\n",
    "                f'Majority vote: V5 + V8 + V10(t={best_threshold:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*70)\n",
    "print('FINAL SUMMARY')\n",
    "print('='*70)\n",
    "print(f'\\nMulti-seed ensemble CV:          {ms_acc:.5f} (vs V5 single-seed: {single_acc:.5f})')\n",
    "print(f'Optimal threshold:               {best_threshold:.3f} (CV: {best_acc:.5f})')\n",
    "print(f'Predictions changed by threshold: {n_changed}')\n",
    "print(f'\\nSubmission files generated: 4')\n",
    "print(f'  1. submission_v10_multiseed.csv  — safest (multi-seed, t=0.500)')\n",
    "print(f'  2. submission_v10_optimal_t.csv  — best CV (multi-seed, t={best_threshold:.3f})')\n",
    "print(f'  3. submission_v10_blend.csv      — consensus (V5+V8+V10 majority vote)')\n",
    "print(f'  4. submission_v10_blend_opt.csv  — consensus + optimal threshold')\n",
    "print(f'\\nRecommendation: Submit #3 (blend) first — it leverages the proven V5 and V8 submissions')\n",
    "print(f'                Then #1 (multi-seed) as backup')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
